#!/usr/bin/perl

=head1 NAME

whwhence - Discover how data sets were computed on the cloud

=head1 SYNOPSIS

 whwhence [options] jobid[@warehousename]
 whwhence [options] locator[,locator,...][@warehousename]

=head1 DESCRIPTION

whwhence(1p) tells you how a given data set was produced, or how it
could be recomputed, based on the history of jobs that have run on the
cloud.  It also provides a list of "source data" locators.

The premise is that the specified data set can be recomputed by
starting with the displayed source data and re-running the displayed
sequence jobs.

=head1 OPERATION

If a data locator is provided, whwhence(1p) starts by finding a job that
produced that locator as output.  If a job number is given, the
specified job will be the first one displayed.

When a job is displayed, its input locator -- along with any locators
appearing in its knob values -- is added to the set of "source data"
locators.

If a "source data" locator was produced as the output of a job on the
cloud, whwhence(1p) displays the job and removes the locator from the
"source data" set.

When none of the remaining "source data" locators can be found in the
outputs of any jobs, whwhence(1p) outputs the remaining "source data"
locators and stops.

=head1 LIMITATIONS

In many cases, the output of whwhence(1p) corresponds to an entire
workflow and the "source data" locators really are the inputs to the
workflow, but this isn't always the case.  For example, if a
mr-function always outputs a YES or NO output, and a YES answer is
used as an input to a job you're interested in, whwhence(1p) is likely
to come up with a way to compute a YES that has nothing to do with the
workflow that you're interested in, and include lots of irrelevant
source data as a result.

=head1 OPTIONS

=over

=item --skip-thawed

Don't follow freeze/thaw cycles.  By default, when encountering a job
that was started by resuming from a saved state, whwhence(1p) will
also display the earlier job whose state was saved.  With this option,
these earlier portions of the job will be omitted from the output.
The information required to reproduce the workflow -- inputs, outputs,
and job configuration -- will be complete either way.

=item --node-seconds

Show total number of node-seconds allocated to each job (number of
nodes allocated * duration of job)

=item --slots

Show total number of slots (maximum concurrent job steps) allocated in
each job.  The maximum number of slots that were in simultaneous use
during the job might be less than this.

=item --slot-seconds

Show number of slot seconds allocated in each job. This is equal to
CPU seconds, if stepspernode was not specified.

=item --failure-seconds

Show how many slot-seconds were spent executing tasks which ultimately
failed.

=item --success-seconds

Show how many slot-seconds were spent executing tasks which ultimately
succeeded.

=item --idle-seconds

Show how many slot-seconds were spent idle (e.g., waiting for the last
jobs in a level to finish, subsequent job steps not yet queued).

=back

=head1 SEE ALSO

whintro(1p), wh(1p)

=cut

use strict;
use Warehouse;
use Warehouse::Stream;

my %opt;
while ($ARGV[0] =~ /^--(\S+)(?:=(.*))?/)
{
    $opt{$1} = defined($2) ? $2 : 1;
    shift @ARGV;
}

if (@ARGV != 1)
{
    use Pod::Usage;
    pod2usage(-exitval => 1);
}

my %opts;
$opts{warehouse_name} = $1 if $ARGV[0] =~ s/\@(.+)//;
my $whc = new Warehouse (%opts);

my $joblist = $whc->job_list;
my %did;
my %id_to_job;
for my $job (@$joblist)
{
    $id_to_job{$job->{id}} = $job;
}

my %inputdata;
my @todo;
my %depends;

map { /^\d{1,31}$/ ? push (@todo, $id_to_job{$_}) : &enqueue (/([0-9a-f]{32})/g) } @ARGV;

while (@todo)
{
    my $targetjob = shift @todo;
    next if ++$did{$targetjob->{id}} != 1;

    printf "#%d\@%s\n", $targetjob->{id}, $whc->{warehouse_name};
    print_times ($whc->job_stats ($targetjob->{id}));
    printf ("  mrfunction = %s %s\n",
	    $targetjob->{mrfunction},
	    $targetjob->{revision} =~ /^\d{1,5}$/ ? "r".$targetjob->{revision} : $targetjob->{revision});

    if (($opt{"skip-thawed"} && $targetjob->{revision} != -1)
	|| !$targetjob->{thawedfromkey})
    {
	printf "  output = %s\n", $targetjob->{outputkey};
	printf "  input = %s\n", $targetjob->{inputkey};
	my $knobs = $targetjob->{knobs};
	my %unescape = ("n" => "\n", "\\" => "\\");
	$knobs =~ s/\\(.)/$unescape{$1}/ge;
	map { printf "  %s\n", $_ } split (/\n/, $knobs);
	print "\n";

	&enqueue ($targetjob->{inputkey},
		  $targetjob->{knobs});
    }
    else
    {
	printf "  output = %s\n", $targetjob->{outputkey};
	printf ("  thawedfromkey = %s\n", $targetjob->{thawedfromkey});
	unshift @todo, $whc->job_follow_thawedfrom ($targetjob);
    }
}

sub enqueue
{
    my @hashes = map { /([0-9a-f]{32})/g } @_;
    while (@hashes)
    {
	my $upto;
	for ($upto = $#hashes; $upto >= 0; $upto--)
	{
	    my $targethash = join (",", @hashes[0..$upto]);
	    my $jobmade = $whc->job_follow_input ({ inputkey => $targethash });
	    if ($jobmade)
	    {
		unshift @todo, $jobmade;
		splice @hashes, 0, $upto + 1;
		last;
	    }
	}
	if ($upto < 0)
	{
	    ++$upto;
	    $inputdata{shift @hashes} = 1;
	}
    }
}

my %loop_detected;
map {
    if (!$loop_detected{$_} &&
	&check_loop($_, {}))
    {
	warn "$_ is part of a cycle; assuming it is not buildable\n";
	$inputdata{$_} = 1;
    }
} sort keys %depends;

print "\nInputs:\n";
print map { "$_\n" } grep { $_ ne 'd41d8cd98f00b204e9800998ecf8427e' } sort keys %inputdata;


sub check_loop
{
    my $out = shift;
    my $loop_checked = shift;
    return 1 if 1 != ++$loop_checked->{$out};
    for my $in (keys %{$depends{$out}})
    {
	return 1 if &check_loop ($in, $loop_checked);
    }
    return 0;
}

sub print_times
{
    my $job = shift;
    my $metastats = $job->{meta_stats};
    if ($job)
    {
	printf ("  --node-seconds = %d = %d nodes * %d seconds\n",
		$job->{nodeseconds},
		$job->{nnodes},
		$job->{elapsed});
	printf ("  --slot-seconds = %d = %d slots * %d seconds\n",
		$metastats->{slot_seconds},
		$metastats->{slots},
		$job->{elapsed});
	foreach (qw(success failure idle))
	{
	    printf ("  --$_-seconds = %d%s\n",
		    $metastats->{$_."_seconds"},
		    $metastats->{$_."_percent"}
		    ? " = ".$metastats->{$_."_percent"}."%" : "");
	}
    }
}
