#!/usr/bin/perl

use strict;
use Fcntl ':flock';
use Warehouse;
use POSIX;
use Digest::MD5 'md5_hex';
my $whc = new Warehouse;

my %override;
while ($ARGV[0] =~ /^(.*?)=(.*)$/)
{
    $override{$1} = $2;
    shift @ARGV;
}

@ARGV == 2
    or die qq{
usage: $0 default-revision workdir

example: $0 2322 /var/cache/maq-jobs-workdir

};

my ($revision_default, $workdir) = @ARGV;

mkdir "$workdir/datablocks";

my %Job;
my @Job;

my $joblist = $whc->job_list;
if (!$joblist || !@$joblist)
{
    warn "job_list returned nothing; quitting after 10 seconds";
    sleep 10;
    exit 1;
}
for (@$joblist)
{
    $Job{$_->{id}} = $_;
}
@Job = sort { $b->{id} <=> $a->{id} } values %Job;

my %new_job_id;


opendir (D, $workdir) or die "$workdir: $!";
for my $workfile (readdir D)
{
    next if $workfile =~ /\./;
    next if $workfile !~ /^[0-9a-f]{32}/;
    fillflow ($workfile);
}
closedir D;


my %Flow;
sub fillflow
{
    my $in = shift;
    return $Flow{$in} if $Flow{$in};

    my $flow = $Flow{$in} = {};
    $flow->{json} = {};

    $flow->{json}->{input} = { id => $in };
    $flow->{json}->{pipeline} = [];

    $flow->{input_in_manifest} = !-e "$workdir/$in.nomanifest";

    if (-l "$workdir/$in.stored")
    {
	my $inputhash = readlink "$workdir/$in.stored";
	$flow->{json}->{input}->{id} = $inputhash;

	if (!-e "$workdir/$inputhash")
	{
	    open W, ">>", "$workdir/$inputhash";
	    close W;
	}
	if (open L, "<", "$workdir/$in.fetched")
	{
	    my ($url) = <L>;
	    my @stat = stat L;
	    my $localmtime = localtime ($stat[9]);
	    $flow->{json}->{message} = "Downloaded from $url at $localmtime";
	}
    }
    elsif (-e "$workdir/$in.isurl")
    {
	if (open L, "<", "$workdir/$in.isurl")
	{
	    my ($url) = <L>;
	    close L;
	    if (-e "$workdir/$in.fail")
	    {
		my @stat = stat "$workdir/$in.fail";
		my $localmtime = localtime ($stat[9]);
		$flow->{json}->{message} = "Download of $url <b>failed</b> at $localmtime";
	    }
	    elsif (!-e "$workdir/$in.lock")
	    {
		$flow->{json}->{message} = "Source data at $url is queued for downloading.";
		fork_downloader ("$workdir/$in");
	    }
	    else
	    {
		my @stat = stat "$workdir/$in.lock";
		my $localmtime = localtime ($stat[9]);
		$flow->{json}->{message} = "Started downloading from $url at $localmtime.";
	    }
	    close L;
	    $flow->{json}->{input}->{id} = $in;
	}
    }
    elsif (-e "$workdir/$in.isgenome")
    {
	my $me = $flow->{"Prepare for maq"};
	$me->{fasta2bfa} = findjob
	    ( { mrfunction => "fasta2bfa",
		revision => [ 2334, ],
		inputkey => $in,
		knobs => makeknobs
		    ("fasta2bfa",
		     "MAQ_DEB=ec9aba3c23989d66f813589e2d4450db",
		     "REMOVE_LC=0",
		    ),
	      } );
	my $inputpath = $flow->{in_manifest} ? "$in/" : "$in/=/$in.gz";
	$flow->{json}->{pipeline} = [ {
	    label => "Convert to BFA",
	    job => [
		jsonjob ("Request", { outputlinks => ["<a href='http://templeton-controller.freelogy.org/whget.cgi/$inputpath'>input data</a>"], success => 1 }),
		jsonjob ("Convert to BFA", $me->{fasta2bfa}),
		] } ];
	print "# finished ".$flow->{json}->{pipeline}->[0]->{label}." $in\n";
    }
    elsif (-e "$workdir/$in.isreads" && 0)
    {
	my $rhg18 = "99259f4330907e84fe7253bd4e52dd3e";
	my $r55k = "f7703aadfb55c12127c4d51693c85587";
	fillpipeline (make_pipeline_id("maq", $in, $rhg18),
		      $in, $flow,
		      { label => "sol/maq/hg18",
			REFERENCE => $rhg18,
			REFERENCEFILE => "homo_sapiens.bfa",
		    } );
	fillpipeline (make_pipeline_id("maq", $in, $r55k),
		      $in, $flow,
		      { label => "sol/maq/55k",
			REFERENCE => $r55k,
			REFERENCEFILE => "ref.bfa",
		    } );
	fillpipeline (make_pipeline_id("maq/std", $in, $rhg18),
		      $in, $flow,
		      { label => "std/maq/hg18",
			REFERENCE => $rhg18,
			REFERENCEFILE => "homo_sapiens.bfa",
			sol2bfq => ["INPUTFORMAT=std"],
		    } );
	fillpipeline (make_pipeline_id("maq/std", $in, $r55k),
		      $in, $flow,
		      { label => "std/maq/55k",
			REFERENCE => $r55k,
			REFERENCEFILE => "ref.bfa",
			sol2bfq => ["INPUTFORMAT=std"],
		    } );
    }
    elsif (-e "$workdir/$in.ispipeline")
    {
	$flow->{json}->{id} = $in;

	sysopen F, "$workdir/$in.ispipeline", O_RDONLY;
	my @spec = <F>;
	chomp @spec;
	my $whatpipeline = shift @spec;
	$whatpipeline =~ s/^pipeline=//;
	my %override_was = %override;
	my %spec;
	foreach (@spec)
	{
	    my ($k, $v) = split ('=', $_, 2);
	    if ($k =~ m{/}) { $override{$k} = $v; }
	    else { $spec{$k} = $v; }
	}
	if ($whatpipeline eq "maq")
	{
	    if ($spec{"reads"} && $spec{"genome"})
	    {
		fillpipeline ($in,
			      $spec{"reads"},
			      $flow,
			      { label => "maq",
				genome => $spec{"genome"}
			      });
	    }
	    else
	    {
		$flow->{json}->{message} = "Need to specify reads and genome";
	    }
	}
	else
	{
	    $flow->{json}->{message} = "Unknown pipeline: \"$whatpipeline\".";
	}
	%override = %override_was;
    }
    elsif (-e "$workdir/$in.islayout")
    {
	next;
    }
    else
    {
	print "# skipped $in, don\'t know what it is.\n";
	next;
    }

    if (open F, "<", "$workdir/$in.comment")
    {
	local $/ = undef;
	$flow->{json}->{message} = <F>;
    }
    writejson ("$workdir/$in", $flow->{json});
    print "# finished $in\n";
}

sub fillpipeline
{
    my ($id, $in, $flow, $pipeline) = @_;

    my $ref = $pipeline->{REFERENCE};
    my $reffile = $pipeline->{REFERENCEFILE};
    my @jsonjob_reference;

    my $me = $flow->{$pipeline->{label}} = {};

    $me->{outputs} = ["$in input"];

    if (!$ref && $pipeline->{genome})
    {
	$me->{fasta2bfa} = findjob
	    ( { mrfunction => "fasta2bfa",
		revision => [ 2334, ],
		inputkey => $pipeline->{genome},
		knobs => makeknobs
		    ("fasta2bfa",
		     "MAQ_DEB=ec9aba3c23989d66f813589e2d4450db",
		     "REMOVE_LC=0",
		     ),
	      } );
	if ($me->{fasta2bfa} && $me->{fasta2bfa}->{outputkey})
	{
	    $ref = $me->{fasta2bfa}->{outputkey};
	    $reffile = "ref.bfa";
	}
	@jsonjob_reference = (jsonjob ("Prepare reference", $me->{fasta2bfa}));
    }

    $me->{sol2bfq} = findjob
	( { mrfunction => "sol2bfq",
	    revision => [ ($pipeline->{sol2bfq} ? 2356 : 2314), ],
	    inputkey => $in,
	    knobs => makeknobs ("sol2bfq",
				$pipeline->{sol2bfq}
				? @{$pipeline->{sol2bfq}} : (),
		),
	} ) unless $me->{sol2bfq};

    if ($ref && $me->{sol2bfq} && $me->{sol2bfq}->{outputkey})
    {
	$me->{map} = findjob
	    ( { mrfunction => "maq-map",
		revision => [ 2315, ],
		inputkey => $me->{sol2bfq}->{outputkey},
		knobs => makeknobs
		    ("maq-map",
		     "MAQ_DEB=ec9aba3c23989d66f813589e2d4450db",
		     "REFERENCE=$ref",
		     "REFERENCEFILE=$reffile",
		     ),
		} ) unless $me->{map};
    }
    if ($me->{map} && $me->{map}->{outputkey})
    {
	$me->{merge} = findjob
	    ( { mrfunction => "maq-merge",
		revision => [ 2318, ],
		inputkey => $me->{map}->{outputkey},
		knobs => makeknobs
		    ("maq-merge",
		     "MAQ_DEB=ec9aba3c23989d66f813589e2d4450db",
		     "REFERENCE=$ref",
		     "REFERENCEFILE=$reffile",
		     ),
		} ) unless $me->{merge};
	buildoutputs ($me, "merge", "mapcheck.txt");
    }
    if ($me->{merge} && $me->{merge}->{outputkey})
    {
	$me->{mapview} = findjob
	    ( { mrfunction => "maq-mapview",
		revision => [ 2331, ],
		inputkey => $me->{merge}->{outputkey},
		knobs => makeknobs
		    ("maq-mapview",
		     "MAQ_DEB=ec9aba3c23989d66f813589e2d4450db",
		     ),
		} ) unless $me->{mapview};
	buildoutputs ($me, "mapview", "all.aln.txt");
	$me->{assemble} = findjob
	    ( { mrfunction => "maq-assemble",
		revision => [ 2319, ],
		inputkey => $me->{merge}->{outputkey},
		knobs => makeknobs
		    ("maq-assemble",
		     "MAQ_DEB=ec9aba3c23989d66f813589e2d4450db",
		     "REFERENCE=$ref",
		     "REFERENCEFILE=$reffile",
		     ),
		} ) unless $me->{assemble};
    }
    if ($me->{assemble} && $me->{assemble}->{outputkey})
    {
	$me->{cns2x} = findjob
	    ( { mrfunction => "maq-cns2x",
		revision => [ 2328, ],
		inputkey => $me->{assemble}->{outputkey},
		stepspernode => 2,
		nodes => 2,
		knobs => makeknobs
		    ("maq-cns2x",
		     "MAQ_DEB=ec9aba3c23989d66f813589e2d4450db",
		     ),
		} ) unless $me->{cns2x};
	buildoutputs ($me, "cns2x",
		      "cns.fq.txt", "cns.snp.txt", "cns.win.txt");
    }
    if ($me->{cns2x} && $me->{cns2x}->{outputkey})
    {
	$me->{snpfilter} = findjob
	    ( { mrfunction => "maq-snpfilter",
		revision => [ 2346, ],
		inputkey => $me->{cns2x}->{outputkey},
		nodes => 1,
		knobs => makeknobs
		    ("maq-snpfilter",
		     "MAQ_DEB=ec9aba3c23989d66f813589e2d4450db",
		     ),
		} ) unless $me->{snpfilter};
	buildoutputs ($me, "snpfilter",
		      "cns.final.snp.txt");
    }

    if ($me->{snpfilter} && $me->{snpfilter}->{outputkey})
    {
	my $bigmanifesthash = buildbigmanifest
	    ($id, map {
		/^\S+/;
		$&;
	     } @{$me->{outputs}});
	$me->{gzip} = findjob
	    ( { mrfunction => "gzip",
		revision => [ 2394, ],
		inputkey => $bigmanifesthash,
		nodes => 1,
		knobs => makeknobs ("maq-gzip"),
	      } ) unless $me->{gzip} || !$bigmanifesthash;
    }

    my $inputpath = $flow->{in_manifest} ? "$in/" : "$in/=/$in.gz";
    push (@ { $flow->{json}->{pipeline} },
	  { label => $pipeline->{label},
	    image => mapcheck_png ($me->{merge}),
	    job => [
		    jsonjob ("Request", { outputlinks => ["<a href='http://templeton-controller.freelogy.org/whget.cgi/$inputpath'>input data</a>"], success => 1 }),
		    @jsonjob_reference,
		    jsonjob ("Prepare reads", $me->{sol2bfq}),
		    jsonjob ("Map", $me->{map}),
		    jsonjob ("Merge", $me->{merge}),
		    jsonjob ("Mapview", $me->{mapview}),
		    jsonjob ("Assemble", $me->{assemble}),
		    jsonjob ("Consensus", $me->{cns2x}),
		    jsonjob ("SNPfilter", $me->{snpfilter}),
		    jsonjob ("gzip", $me->{gzip}),
		    ] } );

    if ($me->{gzip} && $me->{gzip}->{outputkey})
    {
	symlink $me->{gzip}->{outputkey}, "$workdir/$id.download";
	symlink $me->{gzip}->{finishtime_s}, "$workdir/$id.finishtime_s";
	$flow->{json}->{downloadall} = $id;
    }

    print "# finished ".$pipeline->{label}." $in\n";
}

sub buildbigmanifest
{
    my ($pipeline_id, @outputs) = @_;
    my $bigmanifesthash;
    my $bigmanifest = "";
    if ($bigmanifesthash = readlink "$workdir/$pipeline_id.bigmanifesthash")
    {
	return $bigmanifesthash;
    }
    for (@outputs)
    {
	if (-e "$workdir/$_.nomanifest")
	{
	    my @block;
	    my $length = 0;
	    for (split (",", $_))
	    {
		my $blockhash = blockhash_with_size ($_);
		return undef if !$blockhash;
		push @block, $blockhash;
		$length += $1 if $blockhash =~ m{\+([0-9]+)};
	    }
	    $bigmanifest .= ". @block 0:$length:-\n";
	}
	else
	{
	    $bigmanifest .= $whc->fetch_block ($_);
	}
    }
    $bigmanifest =~ s{^(\S+ (\S+).*:)-\n}{
	$1 . "reads.txt" . (block_is_gz($2) ? ".gz" : "") . "\n";
    }e;
    $bigmanifest =~ s/\n.{600}.*?:cns\.fq\.txt\n/\n/;
    $bigmanifesthash = $whc->store_block (\$bigmanifest);
    symlink $bigmanifesthash, "$workdir/$pipeline_id.bigmanifesthash";
    return $bigmanifesthash;
}

sub blockhash_with_size
{
    my $blockhash = shift;
    my $size;
    if ($blockhash =~ /\+(\d+)/) { return $blockhash; }
    if ($blockhash =~ /^[0-9a-f]{32}/)
    {
	my $md5 = $1;
	my $size = readlink "$workdir/datablocks/$md5.size";
	if (!$size)
	{
	    my $dataref = $whc->fetch_block_ref ($md5);
	    if ($dataref)
	    {
		$size = length $$dataref;
		symlink $size, "$workdir/datablocks/$md5.size";
	    }
	}
    }
    return $blockhash if !$size;
    $blockhash =~ s/(^[0-9a-f]+)/$1+$size/;
    return $blockhash;
}

sub block_is_gz
{
    my ($blockhash) = @_;
    my ($md5) = $blockhash =~ /^([0-9a-f]{32})/;
    my $is_gz = readlink "$workdir/datablocks/$md5.gzip";
    return $is_gz if defined $is_gz;

    my $data = $whc->fetch_block ($blockhash);
    $is_gz = ($data =~ /^[ -\177]{1024}/) ? 1 : 0;
    symlink $is_gz, "$workdir/datablocks/$md5.gzip";
    return $is_gz;
}

sub buildoutputs
{
    my ($pipeline, $joblabel, @filename) = @_;
    my $job = $pipeline->{$joblabel};
    if ($job && $job->{outputkey})
    {
	my $manifest = $job->{outputkey};
	my @outputlinks;
	foreach (@filename)
	{
	    push @outputlinks, "<a href='http://templeton-controller.freelogy.org/whget.cgi/$manifest/$_'>$_</a>";
	}
	$job->{outputlinks} = [@outputlinks];

	$pipeline->{outputs} ||= [];
	push @{$pipeline->{outputs}}, $job->{outputkey} . " $joblabel";
    }
}

sub id_and_output
{
    my $job = shift;
    return "" if !$job;
    return $job->{id}."/".$job->{outputkey} if $job->{outputkey};
    my $steps = $job->{steps_done} + $job->{steps_running} + $job->{steps_todo};
    my $pct = $steps==0 ? "" : " (".int(100*$job->{steps_done}/$steps)."%)";
    return $job->{id}."/".$pct;
}

sub findjob
{
    my $want = shift;
    my $failed;
    my $queued;
    for (@Job)
    {
	if ($_->{revision} >= $want->{revision}->[0]
	    && ($_->{revision} <= $want->{revision}->[1] || !$want->{revision}->[1])
	    && $_->{mrfunction} eq $want->{mrfunction}
	    && $_->{knobs} eq $want->{knobs}
	    && $_->{inputkey} eq $want->{inputkey})
	{
	    $queued = $_ unless $queued || $_->{finishtime} || length ($_->{success});
	    $failed = $_ if !$failed && $_->{success} eq '0';
	    delete $_->{outputkey} if !$_->{success};
	    return $_ if $_->{outputkey};
	}
    }
    mention_failed_job ($failed) if !$queued && $failed;
    return start_new_job ($want)
	if (!$queued &&
	    !$want->{quiet} &&
	    (!$failed
	     || -e "$workdir/retryfailed-".$failed->{id}
	     || $override{retryfailed}));
    return $queued || $failed;
}

sub start_new_job
{
    my $want = shift;
    my $nodes = $want->{nodes} || 1;
    my $moreoptions = "";
    $moreoptions .= " stepspernode=".$want->{stepspernode} if $want->{stepspernode};
    my $revision = $want->{revision}->[1] || $revision_default;
    $revision = $want->{revision}->[0] if $revision < $want->{revision}->[0];
    my $knobs = $want->{knobs};
    $knobs =~ s{=(.*?)(\\n|$)}{='$1' }g;
    my $cmd = "wh job new nodes=$nodes photons=1 revision=$revision mrfunction='".$want->{mrfunction}."' inputkey='".$want->{inputkey}."'$moreoptions $knobs\n";
    return if $new_job_id{$cmd};
    print "$cmd\n";
    my $id = `$cmd`;
    chomp $id;
    print "$id\n";
    return if $id !~ /^\d+$/;
    $new_job_id{$cmd} = $id;
    my $newjoblist = $whc->job_list (id_min => $id, id_max => $id);
    ($Job{$id}) = $newjoblist->[0];
    push @Job, $newjoblist->[0];
    return $Job{$id};
}

sub mention_failed_job
{
    my $job = shift;
    print "# suggest investigating job id=".$job->{id}." -- failed with frozentokey=".$job->{frozentokey}." metakey=".$job->{metakey}."\n";
}

sub makeknobs
{
    my $function = shift @_;
    my $knobs = "";
    foreach (sort @_)
    {
	my ($k) = /^(.*)=/;
	if (exists $override{"$function/$k"})
	{
	    $knobs .= $k."=".$override{"$function/$k"};
	}
	else
	{
	    $knobs .= $_;
	}
	$knobs .= "\\n";
    }
    $knobs =~ s/\\n$//s;
    return $knobs;
}

sub get_job_times
{
    my $job = shift;
    my $atwhichfreeze = shift;
    return {
	nodeseconds => 0,
	elapsed => 0,
	slot_seconds => 0,
	success_seconds => 0,
	failure_seconds => 0,
	} if !$job;
    my $frozen = $whc->job_follow_thawedfrom ($job);
    $frozen = $whc->job_stats ($frozen->{id});

    my $times = get_job_times ($frozen, $job->{thawedfromkey});

    $job = $whc->job_stats ($job->{id});
    my $frozentimes;
    if ($atwhichfreeze
	&& $job->{meta_stats}->{frozentokeys}
	&& ($frozentimes = $job->{meta_stats}->{frozentokeys}->{$atwhichfreeze}))
    {
	printf STDERR ("Adding stats from %d at t=%d: %d elapsed, %d success, %d failure, %d idle\n",
		       $job->{id},
		       $frozentimes->{frozentime},
		       $frozentimes->{elapsed},
		       $frozentimes->{success_seconds},
		       $frozentimes->{failure_seconds},
		       $frozentimes->{idle_seconds}) if $ENV{MTR_DEBUG};
	foreach (keys %$times)
	{
	    $times->{$_} += $frozentimes->{$_};
	}
    }
    else
    {
	if ($ENV{MTR_DEBUG})
	{
	    if ($atwhichfreeze)
	    {
		print STDERR "Adding stats from ".$job->{id}.", using entire job because frozentokey ".$atwhichfreeze." not found\n";
	    }
	    else
	    {
		print STDERR "Adding stats from ".$job->{id}."\n";
	    }
	}
	foreach (keys %$times)
	{
	    $times->{$_} += ($job->{meta_stats}->{$_} || $job->{$_});
	}
    }
    return $times;
}

sub jsonjob
{
    my $label = shift;
    my $job = shift;
    my $x = { "label" => $label };
    if ($job)
    {
	if ($job->{id}) { $x->{id} = $job->{id} }
	if ($job->{success}) { $x->{status} = "done" }
	elsif ($job->{success} eq "0") { $x->{status} = "fail" }
	elsif ($job->{finishtime}) { $x->{status} = "fail" }
	elsif ($job->{starttime}) { $x->{status} = "run" }
	elsif ($job->{submittime}) { $x->{status} = "queue" }
	if (($x->{status} eq "run" || $x->{status} eq "fail")
	    &&
	    $job->{steps_done} =~ /\d/)
	{
	    my $steps = $job->{steps_done} + $job->{steps_running} + $job->{steps_todo};
	    $x->{progress} = $job->{steps_done} . "/" . $steps;
	}
	if ($x->{status} eq "done" && $job->{outputlinks})
	{
	    $x->{outputfiles} = $job->{outputlinks};
	}
	if ($x->{status} eq "fail" && $job->{metakey})
	{
	    my $id = $job->{id};
	    my $meta = $job->{metakey};
	    $x->{outputfiles} = [
		qq{<a href="http://templeton-controller.freelogy.org/whget.cgi/$meta.txt">view errors</a>},
		qq{<button id="retry-$id" onclick="pipeline_retryjob($id);">retry job</button>},
		];
	}
    }
    return $x;
}

sub writefile
{
    my $file = shift;
    open F, "+>>$file.tmp";
    flock F, LOCK_EX or do { close F; return; };
    seek F, 0, 0;
    truncate F, 0;
    print F @_;
    close F;
    rename "$file.tmp", "$file";
}

sub writejson
{
    my $file = shift;
    my $json = shift;
    open F, "+>>$file.tmp";
    flock F, LOCK_EX or do { close F; return; };
    seek F, 0, 0;
    truncate F, 0;
    print F "{\n\"workflow\": ".sprintjson("", $json)."\n}\n";
    close F;
    rename "$file.tmp", "$file";
}

sub sprintjson
{
    my $indent = shift;
    my $ob = shift;
    $indent .= "    ";
    if (ref $ob eq "HASH") { return "{ " . join (",\n$indent", map { qq{ "$_": }.sprintjson($indent, $ob->{$_}) } keys %$ob) . " }"; }
    if (ref $ob eq "ARRAY") { return "[ " . join (",\n$indent", map { sprintjson($indent, $_) } @$ob) . " ]"; }
    if (ref $ob eq "SCALAR") { return qq{"} . jsonquote($$ob) . qq{"}; }
    return qq{"} . jsonquote($ob) . qq{"};
}

sub jsonquote
{
    local $_ = shift;
    s/([\\\"\'])/\\$1/gs;
    s/\n/\\n/g;
    $_;
}

sub fork_downloader
{
    my $workfile = shift;
    my $child = fork();
    return if $child;
    return if !defined $child;
    exit 0 unless open L, "+>>", $workfile;
    exit 0 unless flock L, LOCK_EX;
    exit 1 unless open U, "<", "$workfile.isurl";
    my ($url) = <U>;
    my $url_quoted = $url;
    $url_quoted =~ s/\'/\'\\\'\'/g;

    sysopen (F, "$workfile.lock", O_WRONLY|O_CREAT|O_EXCL) or exit 1;
    syswrite F, $url;
    close F;

    my $key = `wget -O - '$url_quoted' 2>>$workfile.wget-log | whput --in-manifest -`;
    chomp $key;
    if ($?)
    {
	sysopen (F, "$workfile.fail", O_WRONLY|O_CREAT|O_EXCL);
	close F;
	exit 0;
    }
    $key =~ s/\+[^,]*//g;
    symlink "$key", "$workfile.stored";
    rename "$workfile.lock", "$workfile.fetched";
    if (sysopen F, "$workdir/$key.comment", O_WRONLY|O_CREAT|O_EXCL)
    {
	syswrite F, scrub_auth ($url);
	close F;
    }
    exit 0;
}

sub scrub_auth
{
    local $_ = shift;
    s{^([^/]+//)[^/]+\@}{$1***:***\@};
    $_;
}


sub mapcheck_png
{
    my $me = shift;
    return "" if !$me;
    my $datahash = $me->{outputkey};
    return "" if !$datahash;
    my $pngpath = "$workdir/images/$datahash.mapcheck.png";
    if (-e $pngpath)
    {
	return "images/$datahash.mapcheck.png";
    }
    elsif (!-d "$workdir/images")
    {
	mkdir "$workdir/images";
    }
    if (sysopen F, "$pngpath.tmp", O_WRONLY|O_CREAT|O_EXCL)
    {
	my $child = fork();
	if ($child || !defined $child) { close F; return ""; }

	my $mapcheck_r = $0;
	$mapcheck_r =~ s{[^/]*$}{maq-mapcheck.r};
	system (qq{whget '$datahash/mapcheck.txt' - | egrep '^ *[0-9]' | perl -ne 'print ((split(":"))[2],"\\n")' > '$pngpath.in'})
	    == 0 or do { unlink "$pngpath.in", "$pngpath.tmp"; die "whget|egrep exited $?"; };
	system (qq{R --no-save --args infile="$pngpath.in" graph_w=3 graph_h=4 imagefile="$pngpath" < $mapcheck_r})
	    == 0 or do { unlink "$pngpath.in", "$pngpath.tmp"; die "R exited $?"; };
	unlink "$pngpath.in", "$pngpath.tmp";
	exit 0;
    }
}

sub make_pipeline_id
{
    my ($pipeline, $reads, $ref) = @_;
    return md5_hex ("pipeline=$pipeline\nreads=$reads\ngenome=$ref\n");
}

__END__

client          apache          downloader      status
----------------------------------------------------------------
submit url
                w umd5.isurl.tmp
                w umd5.isurl
                                                r umd5.isurl
                w umd5
                                w umd5
                                l umd5
                                r umd5.isurl
                                w umd5.lock
                                l umd5.lock
                                download
                                w umd5.stored@
                                w umd5.fetched
                                                r umd5.stored@
