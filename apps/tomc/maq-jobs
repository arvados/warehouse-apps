#!/usr/bin/perl

use strict;
use Fcntl ':flock';
use Warehouse;
use POSIX;
use Digest::MD5 'md5_hex';
my $whc = new Warehouse;

$| = 1;

my %override;
while ($ARGV[0] =~ /^(.*?)=(.*)$/)
{
    $override{$1} = $2;
    shift @ARGV;
}

@ARGV == 2
    or die qq{
usage: $0 default-revision workdir

example: $0 2322 /var/cache/maq-jobs-workdir

};

my ($revision_default, $workdir) = @ARGV;

mkdir "$workdir/datablocks";

my %Job;
my @Job;

my $joblist = $whc->job_list;
if (!$joblist || !@$joblist)
{
    warn "job_list returned nothing; quitting after 10 seconds";
    sleep 10;
    exit 1;
}
for (@$joblist)
{
    $Job{$_->{id}} = $_;
}
@Job = sort { $b->{id} <=> $a->{id} } values %Job;

my %new_job_id;

my $mychildren = 0;
opendir (D, $workdir) or die "$workdir: $!";
for my $workfile (sort readdir D)
{
    next if $workfile =~ /\./;
    next if $workfile !~ /^[0-9a-f]{32}/;
    fillflow ($workfile);
}
closedir D;
--$mychildren while 0 < wait;
exit 0;



my %Flow;
sub fillflow
{
    my $in = shift;
    return $Flow{$in} if $Flow{$in};

    my $flow = $Flow{$in} = {};
    $flow->{json} = {};

    $flow->{json}->{input} = { id => $in };
    $flow->{json}->{pipeline} = [];

    $flow->{input_in_manifest} = !-e "$workdir/$in.nomanifest";

    if (-l "$workdir/$in.stored")
    {
	my $inputhash = readlink "$workdir/$in.stored";
	$flow->{json}->{input}->{id} = $inputhash;

	if (!-e "$workdir/$inputhash")
	{
	    open W, ">>", "$workdir/$inputhash";
	    close W;
	}
	if (open L, "<", "$workdir/$in.fetched")
	{
	    my ($url) = <L>;
	    my @stat = stat L;
	    my $localmtime = localtime ($stat[9]);
	    $flow->{json}->{message} = "Downloaded from $url at $localmtime";
	}
    }
    elsif (-e "$workdir/$in.isurl")
    {
	if (open L, "<", "$workdir/$in.isurl")
	{
	    my ($url) = <L>;
	    close L;
	    if (-e "$workdir/$in.fail")
	    {
		my @stat = stat "$workdir/$in.fail";
		my $localmtime = localtime ($stat[9]);
		$flow->{json}->{message} = "Download of $url <b>failed</b> at $localmtime";
	    }
	    elsif (!-e "$workdir/$in.lock")
	    {
		$flow->{json}->{message} = "Source data at $url is queued for downloading.";
		fork_downloader ("$workdir/$in");
	    }
	    else
	    {
		my @stat = stat "$workdir/$in.lock";
		my $localmtime = localtime ($stat[9]);
		$flow->{json}->{message} = "Started downloading from $url at $localmtime.";
	    }
	    close L;
	    $flow->{json}->{input}->{id} = $in;
	}
    }
    elsif (-e "$workdir/$in.isgenome")
    {
	my $me = $flow->{"Prepare for maq"};
	$me->{fasta2bfa} = findjob
	    ( { mrfunction => "fasta2bfa",
		revision => [ 2334, ],
		inputkey => $in,
		knobs => makeknobs
		    ("fasta2bfa",
		     "MAQ_DEB=ec9aba3c23989d66f813589e2d4450db",
		     "REMOVE_LC=0",
		    ),
	      } );
	my $inputpath = $flow->{input_in_manifest} ? "$in/" : "$in/=/$in.gz";
	$flow->{json}->{pipeline} = [ {
	    label => "Convert to BFA",
	    job => [
		jsonjob ("Request", { outputlinks => ["<a href='whget.cgi/$inputpath'>input data</a>"], success => 1 }),
		jsonjob ("Convert to BFA", $me->{fasta2bfa}),
		] } ];
	print "# finished ".$flow->{json}->{pipeline}->[0]->{label}." $in\n"
	    if $override{debug};
    }
    elsif (-e "$workdir/$in.ispipeline")
    {
	$flow->{json}->{id} = $in;

	sysopen F, "$workdir/$in.ispipeline", O_RDONLY;
	my @spec = <F>;
	chomp @spec;
	my $whatpipeline = shift @spec;
	$whatpipeline =~ s/^pipeline=//;
	my %override_was = %override;
	my %spec;
	foreach (@spec)
	{
	    my ($k, $v) = split ('=', $_, 2);
	    if ($k =~ m{/}) { $override{$k} = $v; }
	    else { $spec{$k} = $v; }
	}
	if ($whatpipeline eq "maq")
	{
	    if ($spec{"reads"} && $spec{"genome"})
	    {
		my $pipeline = {
		    label => "maq",
		    genome => $spec{"genome"},
		    input => \%spec,
		};
		$pipeline->{sol2bfq} = ["INPUTFORMAT=std"]
		    unless (-e "$workdir/".$spec{"reads"}.".issolexa");
		maq_pipeline ($in,
			      $spec{"reads"},
			      $flow,
			      $pipeline);
	    }
	    else
	    {
		$flow->{json}->{message} = "Need to specify reads and genome";
	    }
	}
	elsif ($whatpipeline eq "affyscan")
	{
	    if ($spec{"affyscan"} && $spec{"affymap"})
	    {
		my $pipeline = {
		    label => "affyscan",
		    input => \%spec,
		};
		affyscan_pipeline ($in,
				   $flow,
				   $pipeline);
	    }
	    else
	    {
		$flow->{json}->{message} = "Need to specify affyscan and affymap";
	    }
	}
	elsif ($whatpipeline eq "concordance")
	{
	    if ($spec{"layout0"} && $spec{"layout1"})
	    {
		concordance_pipeline ($in,
				      $flow,
				      { label => "concordance",
					input => \%spec });
	    }
	    else
	    {
		$flow->{json}->{message} = "Need to specify layout0 and layout1";
	    }
	}
	else
	{
	    $flow->{json}->{message} = "Unknown pipeline: \"$whatpipeline\".";
	}
	%override = %override_was;
    }
    elsif (-e "$workdir/$in.islayout")
    {
	next;
    }
    else
    {
	print "# skipped $in, don\'t know what it is.\n"
	    if $override{debug};
	next;
    }

    if (open F, "<", "$workdir/$in.comment")
    {
	local $/ = undef;
	$flow->{json}->{message} = <F>;
    }
    writejson ("$workdir/$in", $flow->{json});
    print "# finished $in\n"
	if $override{debug};
}

sub concordance_pipeline
{
    my ($id, $flow, $pipeline) = @_;

    my $me = $flow->{$pipeline->{label}} = {};

    my @jsonjobs;
    push (@ { $flow->{json}->{pipeline} },
	  { label => $pipeline->{label},
	    job => \@jsonjobs });

    my $ypipelines = &get_layout ($pipeline->{input}->{"layout0"});
    my $xpipelines = &get_layout ($pipeline->{input}->{"layout1"});

    my $htmlfile = "$workdir/images/$id.html";
    &build_concordance_chart ($id, $flow, $pipeline, $htmlfile, $xpipelines, $ypipelines);
    if (-s $htmlfile)
    {
	$me->{"concordance"} = { success => 1, outputlinks => ["<a href=\"cache/images/$id.html\">concordance</a>"], outputkey => "$id.html" };
    }
    push @jsonjobs, &jsonjob ("Concordance", $me->{"concordance"});

    &build_snplist_union ($id, $flow, $pipeline, $ypipelines);

    my $n = 0;
    my @snpagree;
    my $snpagree_ready = 1;
    my @prepreads;
    my $prepreads_ready = 1;
    my @mapviews;
    my $mapviews_ready = 1;
    my @covered_bp;
    my @notable_knobs;
    for (@$ypipelines)
    {
	++$n;

	my $prepreads = $Job { $_->{Preparereads}->{id} };
	my $snpdetail = $Job { $_->{Pileupfilteredcalls}->{id} };
	my $mapview = $Job { $_->{Mapview}->{id} };
	my $assemble = $Job { $_->{Assemble}->{id} };
	my $merge = $Job { $_->{Merge}->{id} };

	push @covered_bp, "--";
	if ($merge && $merge->{outputkey})
	{
	    my $mapcheck = &local_cache ($merge->{outputkey}."/mapcheck.txt");
	    if ($mapcheck =~ /Length of non-gap regions covered by reads:\s*(\d+)/)
	    {
		$covered_bp[-1] = $1;
	    }
	}

	if ($prepreads && $prepreads->{inputkey})
	{
	    if ($prepreads = &fix_nomanifest ($prepreads->{inputkey}))
	    {
		push @prepreads, $prepreads;
	    } else { $prepreads_ready = 0; }
	} else { $prepreads_ready = 0; }

	if ($mapview && $mapview->{outputkey})
	{
	    push @mapviews, $mapview->{outputkey};
	} else { $mapviews_ready = 0; }

	if ($me->{snplistunion} &&
	    $me->{snplistunion}->{outputkey} &&
	    $assemble &&
	    $assemble->{outputkey})
	{
	    $me->{"cnsfilter$n"} = findjob
		( { mrfunction => "filefilter",
		    revision => [ 2622, ],
		    inputkey => $assemble->{outputkey},
		    knobs => makeknobs
			("cnsfilter",
			 "COMMAND=mrs-maq-cns2view|mrs-reftranslate|mrs-maq-alnfilter|mrs-maq /usr/bin/maq.pl SNPfilter -q 40 -w 5 -N 2 -d 1 -D 256 -n 20 -",
			 "OUTPUTNAME=snplist.txt",
			 "SNPREFERENCE=".$me->{snplistunion}->{outputkey}."/snplist.txt",
			),
		  } );
	}
	push @jsonjobs, jsonjob ("cnsfilter$n", $me->{"cnsfilter$n"});
	if ($me->{"cnsfilter$n"} &&
	    $me->{"cnsfilter$n"}->{outputkey} &&
	    $snpdetail &&
	    $snpdetail->{knobs} &&
	    $mapview &&
	    $mapview->{outputkey})
	{
	    my @knobs;
	    push @knobs, "SNPCALL_MIN_COVER=$1"
		if $snpdetail->{knobs} =~ /SNPCALL_MIN_COVER=(\d+)/;
	    push @knobs, "SNPCALL_MIN_STARTS=$1"
		if $snpdetail->{knobs} =~ /SNPCALL_MIN_STARTS=(\d+)/;
	    @notable_knobs = @knobs;

	    $me->{"snpdetail$n"} = findjob
		( { mrfunction => "filefilter",
		    revision => [ 2631, ],
		    inputkey => $mapview->{outputkey},
		    knobs => makeknobs
			("snpdetail",
			 "COMMAND=mrs-reftranslate|mrs-maq-alnfilter",
			 "OUTPUTNAME=snplist.txt",
			 "SNPREFERENCE=".$me->{"cnsfilter$n"}->{"outputkey"}.",".$me->{"snplistunion"}->{"outputkey"}."/",
			 "WANT_SNPS=1",
			 @knobs,
			),
		  } );
	}
	if ($me->{"snpdetail$n"} && $me->{"snpdetail$n"}->{outputkey})
	{
	    $me->{"snpdetail$n"}->{outputlinks} =
		["<a href='snpdig.cgi/call-".$me->{"snpdetail$n"}->{outputkey}."'>snpdig/call</a>",
		 "<a href='snpdig.cgi/nocall-".$me->{"snpdetail$n"}->{outputkey}."'>snpdig/nocall</a>"];
	    push @snpagree, $me->{"snpdetail$n"}->{outputkey};
	}
	else
	{
	    $snpagree_ready = 0;
	}
	push @jsonjobs, &jsonjob ("snpdetail$n", $me->{"snpdetail$n"});
    }

    if ($prepreads_ready)
    {
	for (@prepreads)
	{
	    my $allreads = join (",", @prepreads);
	    $me->{"readstats"} = findjob
		( { mrfunction => "filefilter",
		    revision => [ 2618, ],
		    inputkey => $allreads,
		    knobs => makeknobs
			("readstats",
			 "COMMAND=wc -l | (read a; echo \$MR_ID \$((\$a/4)) )",
			 "OUTPUTNAME=readstats%N.txt",
			),
		  } );
	}
	if ($me->{"readstats"})
	{
	    my $stathash = $me->{"readstats"}->{"outputkey"};
	    if ($stathash)
	    {
		if (!-s "$workdir/images/$stathash.txt")
		{
		    print "whget $stathash/ -> cache/images/$stathash.txt\n";
		    system (qq{whget -r "$stathash/" - > "$workdir/images/$stathash.txt"});
		}
		$me->{"readstats"}->{outputlinks} =
		    ["<a href='cache/images/$stathash.txt'>readstats.txt</a>"];
	    }
	}
    }
    push @jsonjobs, &jsonjob ("readstats", $me->{"readstats"});

    if ($mapviews_ready)
    {
	for (@mapviews)
	{
	    my $allmapviews = join (",", @mapviews);
	    $me->{"placestats"} = findjob
		( { mrfunction => "filefilter",
		    revision => [ 2618, ],
		    inputkey => $allmapviews,
		    knobs => makeknobs
			("placestats",
			 "COMMAND=cut -f1|sort -u|wc -l|(read a; echo \$MR_ID \$a)",
			 "OUTPUTNAME=count_reads_placed.txt",
			),
		  } );
	}
	if ($me->{"placestats"})
	{
	    my $stathash = $me->{"placestats"}->{"outputkey"};
	    if ($stathash)
	    {
		if (!-s "$workdir/images/$stathash.txt")
		{
		    print "whget $stathash/ -> cache/images/$stathash.txt\n";
		    system (qq{whget -r "$stathash/" - > "$workdir/images/$stathash.txt"});
		}
		$me->{"placestats"}->{outputlinks} =
		    ["<a href='cache/images/$stathash.txt'>placestats.txt</a>"];
	    }
	}
    }
    push @jsonjobs, &jsonjob ("placestats", $me->{"placestats"});

    if (!grep { /--/ } @covered_bp)
    {
	my $N = 0;
	my $cbp = join ("", map { ++$N; "$N $_\n" } @covered_bp);
	my $cbphash = md5_hex ($cbp);
	if (!-s "$workdir/images/$cbphash.txt")
	{
	    open C, ">", "$workdir/images/$cbphash.txt";
	    print C $cbp;
	    close C;
	}
	push @jsonjobs, &jsonjob ("coverstats", $me->{"coverstats"} = { outputlinks => ["<a href='cache/images/$cbphash.txt'>cbpstats.txt</a>"], success => 1, outputkey => $cbphash }),
    }

    if ($snpagree_ready)
    {
	for my $n (0..$#$ypipelines)
	{
	    my @snpdig = @snpagree;
	    unshift @snpdig, splice @snpdig, $n, 1;
	    my $url = "snpdig.cgi/call-".join(";", @snpdig);
	    for (@jsonjobs)
	    {
		if ($_->{label} eq "snpdetail".($n+1))
		{
		    push @ { $_->{outputfiles} }, "<a href='$url'>snpdig/allcalls</a>";
		}
	    }
	}

	my $allsnplists = join (",", @snpagree);
 	$me->{"snplist2bed"} = findjob
 	    ( { mrfunction => "filefilter",
 		revision => [ 2658, ],
 		inputkey => $allsnplists,
 		knobs => makeknobs
 		    ("snplist2bed",
 		     "COMMAND=egrep ^chr | cut -f1-4 | perl -ne 'print if /[A-MO-WYZ]\$/' | mrs-snplist2bed",
 		     "OUTPUTNAME=snplist%N.bed",
		     "POPULATION_SNPS_ONLY=1",
		     $pipeline->{input}->{"snplist"}
		     ? ("SNPREFERENCE=".$pipeline->{input}->{"snplist"}."/")
		     : ()
 		    ),
 	      } );
	&buildoutputs ($me, "snplist2bed", map { "snplist$_.bed" } (1..(1+$#snpagree)));
	$me->{"snpstats"} = findjob
	    ( { mrfunction => "filefilter",
		revision => [ 2660, ],
		inputkey => $allsnplists,
		knobs => makeknobs
		    ("snpstats",
		     "COMMAND=mrs-snplist-stats",
		     "OUTPUTNAME=snpstats%N.txt",
		     "POPULATION_SNPS_ONLY=1",
		     $pipeline->{input}->{"snplist"}
		     ? ("SNPREFERENCE=".$pipeline->{input}->{"snplist"}."/")
		     : ()
		    ),
	      } );
	if ($me->{"snpstats"})
	{
	    my $stathash = $me->{"snpstats"}->{"outputkey"};
	    if ($stathash)
	    {
		if (!-s "$workdir/images/$stathash.txt")
		{
		    print "whget $stathash/ -> cache/images/$stathash.txt\n";
		    system (qq{whget -r "$stathash/" - > "$workdir/images/$stathash.txt"});
		}
		$me->{"snpstats"}->{outputlinks} =
		    ["<a href='cache/images/$stathash.txt'>snpstats.txt</a>"];
	    }
	}
    }
    push @jsonjobs, &jsonjob ("snplist2bed", $me->{"snplist2bed"});
    push @jsonjobs, &jsonjob ("snpstats", $me->{"snpstats"});

    if ($me->{"readstats"} && $me->{"readstats"}->{"outputkey"} &&
	$me->{"placestats"} && $me->{"placestats"}->{"outputkey"} &&
	$me->{"coverstats"} && $me->{"coverstats"}->{"outputkey"} &&
	$me->{"snpstats"} && $me->{"snpstats"}->{"outputkey"})
    {
	push @jsonjobs, &jsonjob ("allstats", { outputlinks => ["<a href='allstats.cgi?$id'>allstats</a>"], success => 1 }),
    }

    my $layout0 = $pipeline->{input}->{"layout0"};
    my $layout1 = $pipeline->{input}->{"layout1"};
    $flow->{json}->{pipeline}->[-1]->{html} .=
	"<a href=\"./?$layout0\">View \"y\" layout</a><br /><br /><a href=\"./?$layout1\">View \"x\" layout</a><br /><br />&nbsp;";
}

sub local_cache
{
    my $hash_path = shift;
    my $cache_file = $hash_path;
    $cache_file =~ s{/$}{};
    $cache_file =~ s{/}{--}g;
    $cache_file .= ".txt" if $cache_file !~ /\./;
    $cache_file = "$workdir/images/$cache_file";
    if (!-s $cache_file)
    {
	print "whget -r $hash_path -> $cache_file\n";
	system (qq{whget -r "$hash_path" - > "$cache_file"});
    }
    if (-s $cache_file)
    {
	if (open C, "<", $cache_file)
	{
	    local $/ = undef;
	    my $data = <C>;
	    return $data if close C;
	}
    }
    return undef;
}

sub fix_nomanifest
{
    my ($hash) = @_;
    if (!-e "$workdir/$hash.nomanifest")
    {
	return $hash;
    }
    if (my $mhash = readlink ("$workdir/$hash.asmanifest"))
    {
	return $mhash;
    }
    my $gz = block_is_binary ($hash) ? ".gz" : "";
    my $dhashes =
	join (" ", map { &blockhash_with_size ($_) } split (",", $hash));
    my $dsize = 0;
    $dsize += $1 while $dhashes =~ /\S*\+(\d+)\S*/g;
    my $mhash = $whc->store_block (". $dhashes 0:$dsize:reads.txt$gz\n");
    if ($mhash)
    {
	symlink $mhash, "$workdir/$hash.asmanifest";
	return $mhash;
    }
    return undef;
}

sub get_layout
{
    my ($layouthash) = @_;

    my $layoutfile = "$workdir/$layouthash";
    open L, "<", $layoutfile or return;
    local $/ = undef;
    my $layoutdata = <L>;
    my @pipelinefiles;
    while ($layoutdata =~ m{"id": "(.*?)"}g)
    {
	push @pipelinefiles, $1;
    }
    close L;
    my @pipelines;
    foreach (@pipelinefiles)
    {
	open P, "<", "$workdir/".$_ or return undef;
	push @pipelines, { id => $_ };
	my $pipelinejson = <P>;
	while ($pipelinejson =~ m{"summary": "(\S+) (\d+) (\d+) (\S*)}g)
	{
	    $pipelines[-1]->{$1} = { id => $2 };
	    $pipelines[-1]->{$1}->{outputkey} = $4 if $3;
	}
	close P;
    }
    return \@pipelines;
}

sub build_concordance_chart
{
    my ($id, $flow, $pipeline, $outfile, $xref, $yref) = @_;
    my @x = @$xref;
    my @y = @$yref;

    my $last_job_finish;
    for (@x, @y)
    {
	my $pipelinehash = $_->{"id"};
	my $pipelinefile = "$workdir/$pipelinehash.ispipeline";
	my $inhash;
	map { $inhash=$2 if /^(reads|affyscan)=(\S+)/ } <P>
	    if open P, "<", $pipelinefile;
	close P;
	my $comment = "";
	($comment) = <C> if open C, "<", "$workdir/$inhash.comment";
	close C;
	my $snplistsummary =
	    $_->{"Pileupfilteredcalls"} ||
	    $_->{"LookupSNPIDs"};
	return if !$snplistsummary;
	my $snplistoutput = $snplistsummary->{"outputkey"};
	return if !$snplistoutput;

	my $ft = $Job { $snplistsummary->{"id"} }->{"finishtime_s"};
	$last_job_finish = $ft if $last_job_finish < $ft;

	$_ = $snplistoutput."/:".$comment;
    }

    return if (-s $outfile &&
	       (time - ((-M $outfile) * 86400)) > $last_job_finish);

    print "Running snplist-agree for pipeline $id\n";

    --$mychildren while 0 < waitpid (-1, WNOHANG);
    my $childsupervisor = $mychildren < 1 ? fork() : undef;
    if ($childsupervisor)
    {
	++$mychildren;
	return;
    }
    my ($mybasedir) = $0 =~ /^(.*\/)/;
    my $child = fork();
    if ($child eq 0)
    {
	close STDIN;
	open STDOUT, "+>>", "$outfile.tmp" or die "open $outfile.tmp: $!";
	flock STDOUT, LOCK_EX|LOCK_NB or die "$outfile.tmp already locked\n";
	truncate STDOUT, 0 or die "truncate $outfile.tmp failed: $!";
	seek STDOUT, 0, 0 or die "seek $outfile.tmp failed: $!";
	exec ("${mybasedir}snplist-agree", @x, "--", @y);
	exit 1;
    }
    if ($child)
    {
	wait;
	if ($? == 0)
	{
	    rename "$outfile.tmp", $outfile;
	    if (-s $outfile)
	    {
		exit 0 if defined $childsupervisor;
		return 1;
	    }
	}
    }
    exit 1 if defined $childsupervisor;
    return undef;
}

sub build_snplist_union
{
    my ($id, $flow, $pipeline, $pipelines) = @_;

    my $me = $flow->{$pipeline->{label}};

    my @y = map { $_->{SNPtranslate}->{outputkey} || return } @$pipelines;
    my $in = join(",", @y);
    $me->{snplistunion} = findjob
	( { mrfunction => "filefilter",
	    revision => [ 2596, ],
	    inputkey => $in,
	    knobs => makeknobs ("snplistunion",
				"CONCATENATE=1",
				"OUTPUTNAME=snplist.txt",
				"COMMAND=egrep ^chr|cut -f1,2|sort -nk2|sort -sk1,1|uniq",
		),
	  } ) unless $me->{snplistunion};
    my $joblist = $flow->{json}->{pipeline}->[-1]->{job};
    push @$joblist, jsonjob ("snplist union", $me->{snplistunion});
    buildoutputs ($me, "snplistunion", "snplist.txt");
}

sub affyscan_pipeline
{
    my ($id, $flow, $pipeline) = @_;

    my $me = $flow->{$pipeline->{label}} = {};

    $me->{"outputs"} = [$pipeline->{"input"}->{"affyscan"} . " input"];

    $me->{affy2snplist} = findjob
	( { mrfunction => "filefilter",
	    revision => [ $pipeline->{input}->{probemargin} ? 2592 : 2581, ],
	    inputkey => $pipeline->{input}->{affymap},
	    knobs => makeknobs ("affy2snplist",
				"COMMAND=mrs-affy2snplist",
				"OUTPUTNAME=snplist.txt",
				"CONCATENATE=1",
				$pipeline->{input}->{probemargin}
				? ("PROBEMARGIN=".$pipeline->{input}->{probemargin})
				: (),
				$pipeline->{input}->{genome}
				? ("REFERENCE=".$pipeline->{input}->{genome}."/")
				: (),
		),
	} ) unless $me->{affy2snplist};

    $me->{affyscan2snplist} = findjob
	( { mrfunction => "filefilter",
	    revision => [ 2579, ],
	    inputkey => $pipeline->{input}->{affyscan},
	    knobs => makeknobs ("affyscan2snplist",
				"COMMAND=mrs-affyscan2snplist",
				"OUTPUTNAME=snplist.txt",
				"SNPREFERENCE=".$me->{affy2snplist}->{outputkey}."/",
		),
	} ) unless $me->{affyscan2snplist} || !$me->{affy2snplist} || !$me->{affy2snplist}->{outputkey};
    buildoutputs ($me, "affyscan2snplist", "snplist.txt");

    $me->{"snplist2bed"} = &findjob
	( { mrfunction => "filefilter",
	    revision => [ 2637, ],
	    inputkey => $me->{"affyscan2snplist"}->{"outputkey"},
	    knobs => makeknobs ("snplist2bed",
				"COMMAND=mrs-snplist2bed",
				"OUTPUTNAME=affyscan.bed",
		),
	} ) unless ($me->{"snplist2bed"} ||
		    !$me->{"affyscan2snplist"} ||
		    !$me->{"affyscan2snplist"}->{"outputkey"});
    &buildoutputs ($me, "snplist2bed", "affyscan.bed");

    if ($me->{"snplist2bed"} &&
	$me->{"snplist2bed"}->{"outputkey"})
    {
	my $bigmanifesthash = &buildbigmanifest
	    ($id, map {
		/^\S+/ ? ($&) : ()
	     } @{$me->{"outputs"}});
	$me->{gzip} = findjob
	    ( { mrfunction => "gzip",
		revision => [ 2394, ],
		inputkey => $bigmanifesthash,
		nodes => 1,
		knobs => makeknobs ("affyscan-gzip"),
	      } ) unless $me->{"gzip"} || !$bigmanifesthash;
    }

    my $scan = $pipeline->{input}->{affyscan};
    my $inputpath = $flow->{input_in_manifest} ? "$scan/" : "$scan/=/$scan.gz";
    push (@ { $flow->{json}->{pipeline} },
	  { label => $pipeline->{label},
	    job => [
		    jsonjob ("Request", { outputlinks => ["<a href='whget.cgi/$inputpath'>input data</a>"], success => 1 }),
		    jsonjob ("Prune Affy map", $me->{"affy2snplist"}),
		    jsonjob ("Look up SNP IDs", $me->{"affyscan2snplist"}),
		    jsonjob ("Convert to BED", $me->{"snplist2bed"}),
		    jsonjob ("gzip", $me->{"gzip"}),
		    ] } );

    if ($me->{"gzip"} && $me->{"gzip"}->{"outputkey"})
    {
	symlink $me->{"gzip"}->{"outputkey"}, "$workdir/$id.download";
	symlink $me->{"gzip"}->{"finishtime_s"}, "$workdir/$id.finishtime_s";
	$flow->{"json"}->{"downloadall"} = $id;
    }
}

sub maq_pipeline
{
    my ($id, $in, $flow, $pipeline) = @_;

    my $ref = $pipeline->{REFERENCE};
    my $reffile = $pipeline->{REFERENCEFILE};
    my @jsonjobs;

    my $me = $flow->{$pipeline->{label}} = {};

    $me->{outputs} = ["$in input"];

    if (!$ref && $pipeline->{genome})
    {
	$me->{fasta2bfa} = findjob
	    ( { mrfunction => "fasta2bfa",
		revision => [ 2334, ],
		inputkey => $pipeline->{genome},
		knobs => makeknobs
		    ("fasta2bfa",
		     "MAQ_DEB=ec9aba3c23989d66f813589e2d4450db",
		     "REMOVE_LC=0",
		     ),
	      } );
	if ($me->{fasta2bfa} && $me->{fasta2bfa}->{outputkey})
	{
	    $ref = $me->{fasta2bfa}->{outputkey};
	    $reffile = "ref.bfa";
	}
    }
    push @jsonjobs, jsonjob ("Prepare reference", $me->{fasta2bfa});

    $me->{sol2bfq} = findjob
	( { mrfunction => "sol2bfq",
	    revision => [ ($pipeline->{sol2bfq} ? 2356 : 2314), ],
	    inputkey => $in,
	    knobs => makeknobs ("sol2bfq",
				$pipeline->{sol2bfq}
				? @{$pipeline->{sol2bfq}} : (),
		),
	} ) unless $me->{sol2bfq};
    push @jsonjobs, jsonjob ("Prepare reads", $me->{sol2bfq});

    if ($pipeline->{input}->{affymap})
    {
	$me->{affy2snplist} = findjob
	    ( { mrfunction => "filefilter",
		revision => [ 2610, ],
		inputkey => $pipeline->{input}->{affymap},
		knobs => makeknobs ("affy2snplist",
				    "COMMAND=mrs-affy2snplist",
				    "OUTPUTNAME=snplist.txt",
				    "CONCATENATE=1",
				    $pipeline->{input}->{genome}
				    ? ("REFERENCE=".$pipeline->{input}->{genome}."/")
				    : (),
		    ),
	      } ) unless $me->{affy2snplist};
	push @jsonjobs, jsonjob ("Filter affymap with reference", $me->{affy2snplist});
    }

    if ($ref && $me->{sol2bfq} && $me->{sol2bfq}->{outputkey})
    {
	$me->{map} = findjob
	    ( { mrfunction => "maq-map",
		revision => [ 2315, ],
		inputkey => $me->{sol2bfq}->{outputkey},
		knobs => makeknobs
		    ("maq-map",
		     "MAQ_DEB=ec9aba3c23989d66f813589e2d4450db",
		     "REFERENCE=$ref",
		     "REFERENCEFILE=$reffile",
		     ),
		} ) unless $me->{map};
    }
    push @jsonjobs, jsonjob ("Map", $me->{map});
    if ($me->{map} && $me->{map}->{outputkey})
    {
	$me->{merge} = findjob
	    ( { mrfunction => "maq-merge",
		revision => [ 2318, ],
		inputkey => $me->{map}->{outputkey},
		knobs => makeknobs
		    ("maq-merge",
		     "MAQ_DEB=ec9aba3c23989d66f813589e2d4450db",
		     "REFERENCE=$ref",
		     "REFERENCEFILE=$reffile",
		     ),
		} ) unless $me->{merge};
	buildoutputs ($me, "merge", "mapcheck.txt");
    }
    push @jsonjobs, jsonjob ("Merge", $me->{merge});
    if ($me->{merge} && $me->{merge}->{outputkey})
    {
	$me->{mapview} = findjob
	    ( { mrfunction => "maq-mapview",
		revision => [ 2331, ],
		inputkey => $me->{merge}->{outputkey},
		knobs => makeknobs
		    ("maq-mapview",
		     "MAQ_DEB=ec9aba3c23989d66f813589e2d4450db",
		     ),
		} ) unless $me->{mapview};
	buildoutputs ($me, "mapview", "all.aln.txt");

	$me->{assemble} = findjob
	    ( { mrfunction => "maq-assemble",
		revision => [ 2319, ],
		inputkey => $me->{merge}->{outputkey},
		knobs => makeknobs
		    ("maq-assemble",
		     "MAQ_DEB=ec9aba3c23989d66f813589e2d4450db",
		     "REFERENCE=$ref",
		     "REFERENCEFILE=$reffile",
		     ),
		} ) unless $me->{assemble};
    }
    push @jsonjobs, jsonjob ("Mapview", $me->{mapview});
    push @jsonjobs, jsonjob ("Assemble", $me->{assemble});
    if ($pipeline->{input}->{affymap})
    {
	if ($me->{affy2snplist} &&
	    $me->{affy2snplist}->{outputkey} &&
	    $me->{assemble} &&
	    $me->{assemble}->{outputkey})
	{
	    $me->{cnsfilter} = findjob
		( { mrfunction => "filefilter",
		    revision => [ 2559, ],
		    inputkey => $me->{assemble}->{outputkey},
		    knobs => makeknobs
			("cnsfilter",
			 "COMMAND=mrs-maq-cns2view|mrs-reftranslate|mrs-maq-alnfilter",
			 "OUTPUTNAME=snplist.txt",
			 "SNPREFERENCE=".$me->{affy2snplist}->{outputkey}."/snplist.txt",
			),
		  } ) unless $me->{cnsfilter};
	}
	push @jsonjobs, jsonjob ("Filter calls", $me->{cnsfilter});
    }
    if ($me->{assemble} && $me->{assemble}->{outputkey})
    {
	$me->{cns2x} = findjob
	    ( { mrfunction => "maq-cns2x",
		revision => [ 2328, ],
		inputkey => $me->{assemble}->{outputkey},
		stepspernode => 2,
		nodes => 2,
		knobs => makeknobs
		    ("maq-cns2x",
		     "MAQ_DEB=ec9aba3c23989d66f813589e2d4450db",
		     ),
		} ) unless $me->{cns2x};
	buildoutputs ($me, "cns2x",
		      "cns.fq.txt", "cns.snp.txt", "cns.win.txt");
    }
    push @jsonjobs, jsonjob ("Consensus", $me->{cns2x});
    if ($me->{cns2x} && $me->{cns2x}->{outputkey})
    {
	$me->{snpfilter} = findjob
	    ( { mrfunction => "maq-snpfilter",
		revision => [ 2346, ],
		inputkey => $me->{cns2x}->{outputkey},
		nodes => 1,
		knobs => makeknobs
		    ("maq-snpfilter",
		     "MAQ_DEB=ec9aba3c23989d66f813589e2d4450db",
		     ),
		} ) unless $me->{snpfilter};
	buildoutputs ($me, "snpfilter",
		      "cns.final.snp.txt");
    }
    push @jsonjobs, jsonjob ("SNPfilter", $me->{snpfilter});
    if ($me->{snpfilter} && $me->{snpfilter}->{outputkey})
    {
	$me->{snptranslate} = findjob
	    ( { mrfunction => "awz-stream",
		revision => [ 2462, ],
		inputkey => $me->{snpfilter}->{outputkey},
		nodes => 1,
		knobs => makeknobs
		    ("maq-snptranslate",
		     "FUNCTION=mrs-maq-snptranslate",
		     "OUTPUTNAME=cns.translated.snp.txt",
		     ),
		} ) unless $me->{snptranslate};
	buildoutputs ($me, "snptranslate",
		      "cns.translated.snp.txt");
    }
    push @jsonjobs, jsonjob ("SNPtranslate", $me->{snptranslate});

    my $snplist;
    if ($pipeline->{input}->{affymap})
    {
	$snplist = $me->{cnsfilter}->{outputkey}."/snplist.txt"
	    if $me->{cnsfilter} && $me->{cnsfilter}->{outputkey};
    }
    elsif ($pipeline->{"input"}->{"snplist"})
    {
	$snplist = $me->{"input"}->{"snplist"}."/";
    }
    else
    {
	$snplist = $me->{snptranslate}->{outputkey}."/cns.translated.snp.txt"
	    if $me->{snptranslate} && $me->{snptranslate}->{outputkey};
    }
    if ($snplist &&
	$me->{mapview} &&
	$me->{mapview}->{outputkey})
    {
	my @userknobs;
	push @userknobs, "SNPCALL_MIN_COVER=".$pipeline->{input}->{mincoverage}
	    if $pipeline->{input}->{mincoverage};
	push @userknobs, "SNPCALL_MIN_STARTS=".$pipeline->{input}->{minstarts}
	    if $pipeline->{input}->{minstarts};
	push @userknobs, "SNPCALL_MIN_STARTS=2"
	    if !length ($pipeline->{input}->{minstarts});

	$me->{snpdetail} = findjob
	    ( { mrfunction => "filefilter",
		revision => [ 2596, ],
		inputkey => $me->{mapview}->{outputkey},
		knobs => makeknobs
		    ("snpdetail",
		     "COMMAND=mrs-reftranslate|mrs-maq-alnfilter",
		     "OUTPUTNAME=snplist.txt",
		     "SNPREFERENCE=".$snplist,
		     "WANT_SNPS=1",
		     @userknobs,
		    ),
	      } ) unless $me->{snpdetail};
    }
    buildoutputs ($me, "snpdetail", "snplist.txt");
    push @jsonjobs, jsonjob ("Pileup filtered calls", $me->{snpdetail});

    if ($me->{snptranslate} && $me->{snptranslate}->{outputkey})
    {
	my $bigmanifesthash = buildbigmanifest
	    ($id, map {
		/^\S+/ ? ($&) : ()
	     } @{$me->{outputs}});
	$me->{gzip} = findjob
	    ( { mrfunction => "gzip",
		revision => [ 2394, ],
		inputkey => $bigmanifesthash,
		nodes => 1,
		knobs => makeknobs ("maq-gzip"),
	      } ) unless $me->{gzip} || !$bigmanifesthash;
    }
    push @jsonjobs, jsonjob ("gzip", $me->{gzip});

    my $inputpath = $flow->{input_in_manifest} ? "$in/" : "$in/=/$in.gz";
    push (@ { $flow->{json}->{pipeline} },
	  { label => $pipeline->{label},
	    image => mapcheck_png ($me->{merge}),
	    job => [
		    jsonjob ("Request", { outputlinks => ["<a href='whget.cgi/$inputpath'>input data</a>"], success => 1 }),
		    @jsonjobs,
		    ] } );

    if ($me->{gzip} && $me->{gzip}->{outputkey})
    {
	symlink $me->{gzip}->{outputkey}, "$workdir/$id.download";
	symlink $me->{gzip}->{finishtime_s}, "$workdir/$id.finishtime_s";
	$flow->{json}->{downloadall} = $id;
    }

    print "# finished ".$pipeline->{label}." $in\n"
	if $override{debug};
}

sub buildbigmanifest
{
    my ($pipeline_id, @outputs) = @_;
    my $bigmanifesthash;
    my $bigmanifest = "";
    if ($bigmanifesthash = readlink "$workdir/$pipeline_id.bigmanifesthash")
    {
	return $bigmanifesthash;
    }
    print "Building big output manifest for pipeline $pipeline_id\n";
    for (@outputs)
    {
	if (-e "$workdir/$_.nomanifest")
	{
	    my @block;
	    my $length = 0;
	    for (split (",", $_))
	    {
		my $blockhash = blockhash_with_size ($_);
		return undef if !$blockhash;
		push @block, $blockhash;
		$length += $1 if $blockhash =~ m{\+([0-9]+)};
	    }
	    $bigmanifest .= ". @block 0:$length:-\n";
	}
	else
	{
	    $bigmanifest .= $whc->fetch_block ($_);
	}
    }
    $bigmanifest =~ s{^(\S+ (\S+).*:)-\n}{
	$1 . "reads.txt" . (block_is_binary($2) ? ".gz" : "") . "\n";
    }e;
    $bigmanifest =~ s/\n.{600}.*?:cns\.fq\.txt\n/\n/;
    $bigmanifesthash = $whc->store_block (\$bigmanifest);
    symlink $bigmanifesthash, "$workdir/$pipeline_id.bigmanifesthash";
    return $bigmanifesthash;
}

sub blockhash_with_size
{
    my $blockhash = shift;
    my $size;
    if ($blockhash =~ /\+(\d+)/) { return $blockhash; }
    if ($blockhash =~ /^([0-9a-f]{32})/)
    {
	my $md5 = $1;
	$size = readlink "$workdir/datablocks/$md5.size";
	if (!$size)
	{
	    my $dataref = $whc->fetch_block_ref ($md5);
	    if ($dataref)
	    {
		$size = length $$dataref;
		symlink $size, "$workdir/datablocks/$md5.size";
	    }
	}
    }
    return $blockhash if !$size;
    $blockhash =~ s/(^[0-9a-f]+)/$1+$size/;
    return $blockhash;
}

sub block_is_binary
{
    my ($blockhash) = @_;
    my ($md5) = $blockhash =~ /^([0-9a-f]{32})/;
    my $is_binary = readlink "$workdir/datablocks/$md5.isbinary";
    return $is_binary if defined $is_binary;

    my $data = $whc->fetch_block ($blockhash);
    $is_binary = ($data !~ /^[ -\177]{1024}/) ? 1 : 0;
    symlink $is_binary, "$workdir/datablocks/$md5.isbinary";
    return $is_binary;
}

sub buildoutputs
{
    my ($pipeline, $joblabel, @filename) = @_;
    my $job = $pipeline->{$joblabel};
    if ($job && $job->{outputkey})
    {
	my $manifest = $job->{outputkey};
	my @outputlinks;
	foreach (@filename)
	{
	    push @outputlinks, "<a href='whget.cgi/$manifest/$_'>$_</a>";
	}
	$job->{outputlinks} = [@outputlinks];

	$pipeline->{outputs} ||= [];
	push @{$pipeline->{outputs}}, $job->{outputkey} . " $joblabel";
    }
}

sub id_and_output
{
    my $job = shift;
    return "" if !$job;
    return $job->{id}."/".$job->{outputkey} if $job->{outputkey};
    my $steps = $job->{steps_done} + $job->{steps_running} + $job->{steps_todo};
    my $pct = $steps==0 ? "" : " (".int(100*$job->{steps_done}/$steps)."%)";
    return $job->{id}."/".$pct;
}

sub findjob
{
    my $want = shift;
    my $failed;
    my $queued;
    for (@Job)
    {
	if ($_->{revision} >= $want->{revision}->[0]
	    && ($_->{revision} <= $want->{revision}->[1] || !$want->{revision}->[1])
	    && $_->{mrfunction} eq $want->{mrfunction}
	    && $_->{knobs} eq $want->{knobs}
	    && keys_are_equal ($_->{inputkey}, $want->{inputkey}))
	{
	    delete $_->{outputkey} if !$_->{success};
	    return $_ if $_->{outputkey};
	    $queued = $_ if !$queued && !$_->{finishtime} && !length ($_->{success});
	    $failed = $_ if !$failed && $_->{success} eq '0';
	}
    }
    return $queued if $queued;

    mention_failed_job ($failed) if $failed;
    return start_new_job ($want)
	if (!$want->{quiet} &&
	    (!$failed
	     || -e "$workdir/retryfailed-".$failed->{id}
	     || $override{retryfailed}));
    return $failed;
}

sub keys_are_equal
{
    my ($a, $b) = @_;
    for ($a, $b) { s/\+[^,]*//g }
    return ($a eq $b);
}

sub start_new_job
{
    my $want = shift;
    my $nodes = $want->{nodes} || 1;
    my $moreoptions = "";
    my $revision = $want->{revision}->[1] || $revision_default;
    $revision = $want->{revision}->[0] if $revision < $want->{revision}->[0];
    my %jobspec = ("nodes" => $nodes,
		   "photons" => 1,
		   "revision" => $revision,
		   "mrfunction" => $want->{mrfunction},
		   "inputkey" => $want->{inputkey},
		   "knobs" => $want->{knobs},
	);
    $jobspec{stepspernode} = $want->{stepspernode} if $want->{stepspernode};
    $jobspec{knobs} =~ s/\\(.)/$1 eq "n" ? "\n" : $1/ge;
    my $printable_jobspec
	= join ("", map { "    $_=$jobspec{$_}\n" } sort keys %jobspec);
    $printable_jobspec =~ s/\n(\S)/\n          $1/gs;
    return if exists $new_job_id{$printable_jobspec};

    if (exists $override{newjoblimit} &&
	--$override{newjoblimit} < 0)
    {
	return;
    }

    my $id = $whc->job_new (%jobspec) || -1;
    print ("$id -- queued ",
	   scalar(localtime),
	   "\n",
	   $printable_jobspec);
    $new_job_id{$printable_jobspec} = $id || -1;
    return if $id !~ /^\d+$/;

    my $newjoblist = $whc->job_list (id_min => $id, id_max => $id);
    ($Job{$id}) = $newjoblist->[0];
    push @Job, $newjoblist->[0];
    return $Job{$id};
}

sub mention_failed_job
{
    my $job = shift;
    print "# suggest investigating job id=".$job->{id}." -- failed with frozentokey=".$job->{frozentokey}." metakey=".$job->{metakey}."\n"
	if $override{debug};
}

sub makeknobs
{
    my $function = shift @_;
    my $knobs = "";
    foreach (sort @_)
    {
	my ($k) = /^(.*)=/;
	if (exists $override{"$function/$k"})
	{
	    $knobs .= $k."=".$override{"$function/$k"};
	}
	else
	{
	    $knobs .= $_;
	}
	$knobs .= "\\n";
    }
    $knobs =~ s/\\n$//s;
    return $knobs;
}

sub get_job_times
{
    my $job = shift;
    my $atwhichfreeze = shift;
    return {
	nodeseconds => 0,
	elapsed => 0,
	slot_seconds => 0,
	success_seconds => 0,
	failure_seconds => 0,
	} if !$job;
    my $frozen = $whc->job_follow_thawedfrom ($job);
    $frozen = $whc->job_stats ($frozen->{id});

    my $times = get_job_times ($frozen, $job->{thawedfromkey});

    $job = $whc->job_stats ($job->{id});
    my $frozentimes;
    if ($atwhichfreeze
	&& $job->{meta_stats}->{frozentokeys}
	&& ($frozentimes = $job->{meta_stats}->{frozentokeys}->{$atwhichfreeze}))
    {
	printf STDERR ("Adding stats from %d at t=%d: %d elapsed, %d success, %d failure, %d idle\n",
		       $job->{id},
		       $frozentimes->{frozentime},
		       $frozentimes->{elapsed},
		       $frozentimes->{success_seconds},
		       $frozentimes->{failure_seconds},
		       $frozentimes->{idle_seconds}) if $ENV{MTR_DEBUG};
	foreach (keys %$times)
	{
	    $times->{$_} += $frozentimes->{$_};
	}
    }
    else
    {
	if ($ENV{MTR_DEBUG})
	{
	    if ($atwhichfreeze)
	    {
		print STDERR "Adding stats from ".$job->{id}.", using entire job because frozentokey ".$atwhichfreeze." not found\n";
	    }
	    else
	    {
		print STDERR "Adding stats from ".$job->{id}."\n";
	    }
	}
	foreach (keys %$times)
	{
	    $times->{$_} += ($job->{meta_stats}->{$_} || $job->{$_});
	}
    }
    return $times;
}

sub jsonjob
{
    my $label = shift;
    my $job = shift;
    my $x = { "label" => $label };
    if ($job)
    {
	if ($job->{id}) { $x->{id} = $job->{id} }
	if ($job->{success}) { $x->{status} = "done" }
	elsif ($job->{success} eq "0") { $x->{status} = "fail" }
	elsif ($job->{finishtime}) { $x->{status} = "fail" }
	elsif ($job->{starttime}) { $x->{status} = "run" }
	elsif ($job->{submittime}) { $x->{status} = "queue" }
	if (($x->{status} eq "run" || $x->{status} eq "fail")
	    &&
	    $job->{steps_done} =~ /\d/)
	{
	    my $steps = $job->{steps_done} + $job->{steps_running} + $job->{steps_todo};
	    $x->{progress} = $job->{steps_done} . "/" . $steps;
	}
	if ($x->{status} eq "done" && $job->{outputlinks})
	{
	    $x->{outputfiles} = $job->{outputlinks};
	}
	if ($x->{status} eq "fail")
	{
	    my $id = $job->{id};
	    my $meta = $job->{metakey};
	    $x->{outputfiles} = [
		($meta
		 ? qq{<a href="whget.cgi/$meta.txt">view errors</a>}
		 : ()),
		qq{<button id="retry-$id" onclick="pipeline_retryjob($id);">retry job</button>},
		];
	}
	my $safelabel = $label;
	$safelabel =~ s/\s//g;
	$x->{summary} = join (" ", $safelabel, map { $job->{$_} } qw(id success outputkey metakey));
    }
    return $x;
}

sub writefile
{
    my $file = shift;
    open F, "+>>$file.tmp";
    flock F, LOCK_EX or do { close F; return; };
    seek F, 0, 0;
    truncate F, 0;
    print F @_;
    close F;
    rename "$file.tmp", "$file";
}

sub writejson
{
    my $file = shift;
    my $json = shift;
    open F, "+>>$file.tmp";
    flock F, LOCK_EX or do { close F; return; };
    seek F, 0, 0;
    truncate F, 0;
    print F "{\n\"workflow\": ".sprintjson("", $json)."\n}\n";
    close F;
    rename "$file.tmp", "$file";
}

sub sprintjson
{
    my $indent = shift;
    my $ob = shift;
    $indent .= "    ";
    if (ref $ob eq "HASH") { return "{ " . join (",\n$indent", map { qq{ "$_": }.sprintjson($indent, $ob->{$_}) } keys %$ob) . " }"; }
    if (ref $ob eq "ARRAY") { return "[ " . join (",\n$indent", map { sprintjson($indent, $_) } @$ob) . " ]"; }
    if (ref $ob eq "SCALAR") { return qq{"} . jsonquote($$ob) . qq{"}; }
    return qq{"} . jsonquote($ob) . qq{"};
}

sub jsonquote
{
    local $_ = shift;
    s/([\\\"\'])/\\$1/gs;
    s/\n/\\n/g;
    $_;
}

sub fork_downloader
{
    my $workfile = shift;
    my $child = fork();
    return if $child;
    return if !defined $child;
    exit 0 unless open L, "+>>", $workfile;
    exit 0 unless flock L, LOCK_EX;
    exit 1 unless open U, "<", "$workfile.isurl";
    my ($url) = <U>;
    my $url_quoted = $url;
    $url_quoted =~ s/\'/\'\\\'\'/g;

    sysopen (F, "$workfile.lock", O_WRONLY|O_CREAT|O_EXCL) or exit 1;
    syswrite F, $url;
    close F;

    my $key = `wget -O - '$url_quoted' 2>>$workfile.wget-log | whput --in-manifest -`;
    chomp $key;
    if ($?)
    {
	sysopen (F, "$workfile.fail", O_WRONLY|O_CREAT|O_EXCL);
	close F;
	exit 0;
    }
    $key =~ s/\+[^,]*//g;
    symlink "$key", "$workfile.stored";
    rename "$workfile.lock", "$workfile.fetched";
    if (sysopen F, "$workdir/$key.comment", O_WRONLY|O_CREAT|O_EXCL)
    {
	syswrite F, scrub_auth ($url);
	close F;
    }
    exit 0;
}

sub scrub_auth
{
    local $_ = shift;
    s{^([^/]+//)[^/]+\@}{$1***:***\@};
    $_;
}


sub mapcheck_png
{
    my $me = shift;
    return "" if !$me;
    my $datahash = $me->{outputkey};
    return "" if !$datahash;
    my $pngpath = "$workdir/images/$datahash.mapcheck.png";
    if (-e $pngpath)
    {
	return "images/$datahash.mapcheck.png";
    }
    elsif (!-d "$workdir/images")
    {
	mkdir "$workdir/images";
    }
    if (sysopen F, "$pngpath.tmp", O_WRONLY|O_CREAT|O_EXCL)
    {
	my $child = fork();
	if ($child || !defined $child) { close F; return ""; }

	my $mapcheck_r = $0;
	$mapcheck_r =~ s{[^/]*$}{maq-mapcheck.r};
	system (qq{whget '$datahash/mapcheck.txt' - | egrep '^ *[0-9]' | perl -ne 'print ((split(":"))[2],"\\n")' > '$pngpath.in'})
	    == 0 or do { unlink "$pngpath.in", "$pngpath.tmp"; die "whget|egrep exited $?"; };
	system (qq{R --no-save --args infile="$pngpath.in" graph_w=3 graph_h=4 imagefile="$pngpath" < $mapcheck_r})
	    == 0 or do { unlink "$pngpath.in", "$pngpath.tmp"; die "R exited $?"; };
	unlink "$pngpath.in", "$pngpath.tmp";
	exit 0;
    }
}

sub make_pipeline_id
{
    my ($pipeline, $reads, $ref) = @_;
    return md5_hex ("pipeline=$pipeline\nreads=$reads\ngenome=$ref\n");
}

__END__

client          apache          downloader      status
----------------------------------------------------------------
submit url
                w umd5.isurl.tmp
                w umd5.isurl
                                                r umd5.isurl
                w umd5
                                w umd5
                                l umd5
                                r umd5.isurl
                                w umd5.lock
                                l umd5.lock
                                download
                                w umd5.stored@
                                w umd5.fetched
                                                r umd5.stored@
