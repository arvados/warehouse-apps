#!/usr/bin/perl

use strict;
use Fcntl ':flock';
use Warehouse;
use POSIX;
my $whc = new Warehouse;

my %override;
while ($ARGV[0] =~ /^(.*?)=(.*)$/)
{
    $override{$1} = $2;
    shift @ARGV;
}

@ARGV == 2
    or die qq{
usage: $0 default-revision workdir

example: $0 2322 /var/cache/maq-jobs-workdir

};

my ($revision_default, $workdir) = @ARGV;

my %Job;
my @Job;

my $joblist = $whc->job_list;
for (@$joblist)
{
    $Job{$_->{id}} = $_;
}
@Job = sort { $b->{id} <=> $a->{id} } values %Job;

my %already_did_cmd;


opendir (D, $workdir) or die "$workdir: $!";
for my $workfile (readdir D)
{
    next if $workfile =~ /\./;
    fillflow ($workfile);
}
closedir D;


my %Flow;
sub fillflow
{
    my $in = shift;
    return $Flow{$in} if $Flow{$in};

    my $flow = $Flow{$in} = {};
    $flow->{json} = {};

    $flow->{json}->{input} = { id => $in };
    $flow->{json}->{pipeline} = [];

    if (-l "$workdir/$in.stored")
    {
	my $inputhash = readlink "$workdir/$in.stored";
	$flow->{json}->{input}->{id} = $inputhash;

	if (!-e "$workdir/$inputhash")
	{
	    open W, ">>", "$workdir/$inputhash";
	    close W;
	}
	if (open L, "<", "$workdir/$in.fetched")
	{
	    my ($url) = <L>;
	    my @stat = stat L;
	    my $localmtime = localtime ($stat[9]);
	    $flow->{json}->{message} = "Downloaded from $url at $localmtime";
	}
    }
    elsif (-e "$workdir/$in.isurl")
    {
	if (open L, "<", "$workdir/$in.isurl")
	{
	    my ($url) = <L>;
	    close L;
	    if (-e "$workdir/$in.fail")
	    {
		my @stat = stat "$workdir/$in.fail";
		my $localmtime = localtime ($stat[9]);
		$flow->{json}->{message} = "Download of $url <b>failed</b> at $localmtime";
	    }
	    elsif (!-e "$workdir/$in.lock")
	    {
		$flow->{json}->{message} = "Source data at $url is queued for downloading.";
		fork_downloader ("$workdir/$in");
	    }
	    else
	    {
		my @stat = stat "$workdir/$in.lock";
		my $localmtime = localtime ($stat[9]);
		$flow->{json}->{message} = "Started downloading from $url at $localmtime.";
	    }
	    close L;
	    $flow->{json}->{input}->{id} = $in;
	}
    }
    elsif (-e "$workdir/$in.isgenome")
    {
	my $me = $flow->{"Prepare for maq"};
	$me->{fasta2bfa} = findjob
	    ( { mrfunction => "fasta2bfa",
		revision => [ 2334, ],
		inputkey => $in,
		knobs => makeknobs
		    ("fasta2bfa",
		     "MAQ_DEB=ec9aba3c23989d66f813589e2d4450db",
		     "REMOVE_LC=0",
		    ),
	      } );
	$flow->{json}->{pipeline} = [ {
	    label => "Convert to BFA",
	    job => [
		jsonjob ("Request", { outputfiles => ["<a href='http://templeton-controller.freelogy.org/whget.cgi/$in/=/$in.gz'>input data</a>"], success => 1 }),
		jsonjob ("Convert to BFA", $me->{fasta2bfa}),
		] } ];
	print "# finished ".$flow->{json}->{pipeline}->[0]->{label}." $in\n";
    }
    elsif (-e "$workdir/$in.isreads")
    {
	fillpipeline ($in, $flow,
		      { label => "sol/maq/hg18",
			REFERENCE => "99259f4330907e84fe7253bd4e52dd3e",
			REFERENCEFILE => "homo_sapiens.bfa",
		    } );
	fillpipeline ($in, $flow,
		      { label => "sol/maq/55k",
			REFERENCE => "f7703aadfb55c12127c4d51693c85587",
			REFERENCEFILE => "ref.bfa",
		    } );
	fillpipeline ($in, $flow,
		      { label => "std/maq/hg18",
			REFERENCE => "99259f4330907e84fe7253bd4e52dd3e",
			REFERENCEFILE => "homo_sapiens.bfa",
			sol2bfq => ["INPUTFORMAT=std"],
		    } );
	fillpipeline ($in, $flow,
		      { label => "std/maq/55k",
			REFERENCE => "f7703aadfb55c12127c4d51693c85587",
			REFERENCEFILE => "ref.bfa",
			sol2bfq => ["INPUTFORMAT=std"],
		    } );
    }
    elsif (-e "$workdir/$in.ispipeline")
    {
	$flow->{json}->{id} = $in;

	sysopen F, "$workdir/$in.ispipeline", O_RDONLY;
	my @spec = <F>;
	chomp @spec;
	my $whatpipeline = shift @spec;
	$whatpipeline =~ s/^pipeline=//;
	my %override_was = %override;
	my %spec;
	foreach (@spec)
	{
	    my ($k, $v) = split ('=', $_, 2);
	    if ($k =~ m{/}) { $override{$k} = $v; }
	    else { $spec{$k} = $v; }
	}
	if ($whatpipeline eq "maq")
	{
	    if ($spec{"reads"} && $spec{"genome"})
	    {
		fillpipeline ($spec{"reads"}, $flow,
			      { label => "maq",
				genome => $spec{"genome"}
			      });
	    }
	    else
	    {
		$flow->{json}->{message} = "Need to specify reads and genome1";
	    }
	}
	else
	{
	    $flow->{json}->{message} = "Unknown pipeline: \"$whatpipeline\".";
	}
	%override = %override_was;
    }
    if (open F, "<", "$workdir/$in.comment")
    {
	local $/ = undef;
	$flow->{json}->{message} = <F>;
    }
    writejson ("$workdir/$in", $flow->{json});
    print "# finished $in\n";
}

sub fillpipeline
{
    my ($in, $flow, $pipeline) = @_;

    my $ref = $pipeline->{REFERENCE};
    my $reffile = $pipeline->{REFERENCEFILE};
    my @jsonjob_reference;

    my $me = $flow->{$pipeline->{label}} = {};

    if (!$ref && $pipeline->{genome})
    {
	$me->{fasta2bfa} = findjob
	    ( { mrfunction => "fasta2bfa",
		revision => [ 2334, ],
		inputkey => $pipeline->{genome},
		knobs => makeknobs
		    ("fasta2bfa",
		     "MAQ_DEB=ec9aba3c23989d66f813589e2d4450db",
		     "REMOVE_LC=0",
		     ),
	      } );
	if ($me->{fasta2bfa} && $me->{fasta2bfa}->{outputkey})
	{
	    $ref = $me->{fasta2bfa}->{outputkey};
	    $reffile = "ref.bfa";
	}
	@jsonjob_reference = (jsonjob ("Prepare reference", $me->{fasta2bfa}));
    }

    $me->{sol2bfq} = findjob
	( { mrfunction => "sol2bfq",
	    revision => [ ($pipeline->{sol2bfq} ? 2356 : 2314), ],
	    inputkey => $in,
	    knobs => makeknobs ("sol2bfq",
				$pipeline->{sol2bfq}
				? @{$pipeline->{sol2bfq}} : (),
		),
	} ) unless $me->{sol2bfq};

    if ($ref && $me->{sol2bfq} && $me->{sol2bfq}->{outputkey})
    {
	$me->{map} = findjob
	    ( { mrfunction => "maq-map",
		revision => [ 2315, ],
		inputkey => $me->{sol2bfq}->{outputkey},
		knobs => makeknobs
		    ("maq-map",
		     "MAQ_DEB=ec9aba3c23989d66f813589e2d4450db",
		     "REFERENCE=$ref",
		     "REFERENCEFILE=$reffile",
		     ),
		} ) unless $me->{map};
    }
    if ($me->{map} && $me->{map}->{outputkey})
    {
	$me->{merge} = findjob
	    ( { mrfunction => "maq-merge",
		revision => [ 2318, ],
		inputkey => $me->{map}->{outputkey},
		knobs => makeknobs
		    ("maq-merge",
		     "MAQ_DEB=ec9aba3c23989d66f813589e2d4450db",
		     "REFERENCE=$ref",
		     "REFERENCEFILE=$reffile",
		     ),
		} ) unless $me->{merge};
	buildoutputs ($me->{merge}, "mapcheck.txt");
    }
    if ($me->{merge} && $me->{merge}->{outputkey})
    {
	$me->{mapview} = findjob
	    ( { mrfunction => "maq-mapview",
		revision => [ 2331, ],
		inputkey => $me->{merge}->{outputkey},
		knobs => makeknobs
		    ("maq-mapview",
		     "MAQ_DEB=ec9aba3c23989d66f813589e2d4450db",
		     ),
		} ) unless $me->{mapview};
	buildoutputs ($me->{mapview}, "all.aln.txt");
	$me->{assemble} = findjob
	    ( { mrfunction => "maq-assemble",
		revision => [ 2319, ],
		inputkey => $me->{merge}->{outputkey},
		knobs => makeknobs
		    ("maq-assemble",
		     "MAQ_DEB=ec9aba3c23989d66f813589e2d4450db",
		     "REFERENCE=$ref",
		     "REFERENCEFILE=$reffile",
		     ),
		} ) unless $me->{assemble};
    }
    if ($me->{assemble} && $me->{assemble}->{outputkey})
    {
	$me->{cns2x} = findjob
	    ( { mrfunction => "maq-cns2x",
		revision => [ 2328, ],
		inputkey => $me->{assemble}->{outputkey},
		stepspernode => 2,
		nodes => 2,
		knobs => makeknobs
		    ("maq-cns2x",
		     "MAQ_DEB=ec9aba3c23989d66f813589e2d4450db",
		     ),
		} ) unless $me->{cns2x};
	buildoutputs ($me->{cns2x},
		      "cns.fq.txt", "cns.snp.txt", "cns.win.txt");
    }
    if ($me->{cns2x} && $me->{cns2x}->{outputkey})
    {
	$me->{snpfilter} = findjob
	    ( { mrfunction => "maq-snpfilter",
		revision => [ 2346, ],
		inputkey => $me->{cns2x}->{outputkey},
		nodes => 1,
		knobs => makeknobs
		    ("maq-snpfilter",
		     "MAQ_DEB=ec9aba3c23989d66f813589e2d4450db",
		     ),
		} ) unless $me->{snpfilter};
	buildoutputs ($me->{snpfilter},
		      "cns.final.snp.txt");
    }

    push (@ { $flow->{json}->{pipeline} },
	  { label => $pipeline->{label},
	    image => mapcheck_png ($me->{merge}),
	    job => [
		    jsonjob ("Request", { outputfiles => ["<a href='http://templeton-controller.freelogy.org/whget.cgi/$in/=/$in.gz'>input data</a>"], success => 1 }),
		    @jsonjob_reference,
		    jsonjob ("Prepare reads", $me->{sol2bfq}),
		    jsonjob ("Map", $me->{map}),
		    jsonjob ("Merge", $me->{merge}),
		    jsonjob ("Mapview", $me->{mapview}),
		    jsonjob ("Assemble", $me->{assemble}),
		    jsonjob ("Consensus", $me->{cns2x}),
		    jsonjob ("SNPfilter", $me->{snpfilter}),
		    ] } );

    print "# finished ".$pipeline->{label}." $in\n";
}

sub buildoutputs
{
    my ($job, @filename) = @_;
    if ($job && $job->{outputkey})
    {
	my $manifest = $job->{outputkey};
	my @outputfiles;
	foreach (@filename)
	{
	    push @outputfiles, "<a href='http://templeton-controller.freelogy.org/whget.cgi/$manifest/$_'>$_</a>";
	}
	$job->{outputfiles} = [@outputfiles];
    }
}

sub id_and_output
{
    my $job = shift;
    return "" if !$job;
    return $job->{id}."/".$job->{outputkey} if $job->{outputkey};
    my $steps = $job->{steps_done} + $job->{steps_running} + $job->{steps_todo};
    my $pct = $steps==0 ? "" : " (".int(100*$job->{steps_done}/$steps)."%)";
    return $job->{id}."/".$pct;
}

sub findjob
{
    my $want = shift;
    my $failed;
    my $queued;
    for (@Job)
    {
	if ($_->{revision} >= $want->{revision}->[0]
	    && ($_->{revision} <= $want->{revision}->[1] || !$want->{revision}->[1])
	    && $_->{mrfunction} eq $want->{mrfunction}
	    && $_->{knobs} eq $want->{knobs}
	    && $_->{inputkey} eq $want->{inputkey})
	{
	    $queued = $_ unless $queued || $_->{finishtime} || length ($_->{success});
	    $failed = $_ if !$failed && $_->{success} eq '0';
	    delete $_->{outputkey} if !$_->{success};
	    return $_ if $_->{outputkey};
	}
    }
    mention_failed_job ($failed) if !$queued && $failed;
    suggest_new_job ($want) if !$queued && !$want->{quiet} && (!$failed || $override{retryfailed});
    return $queued || $failed;
}

sub suggest_new_job
{
    my $want = shift;
    my $nodes = $want->{nodes} || 1;
    my $moreoptions = "";
    $moreoptions .= " stepspernode=".$want->{stepspernode} if $want->{stepspernode};
    my $revision = $want->{revision}->[1] || $revision_default;
    $revision = $want->{revision}->[0] if $revision < $want->{revision}->[0];
    my $knobs = $want->{knobs};
    $knobs =~ s{=(.*?)(\\n|$)}{='$1' }g;
    my $cmd = "wh job new nodes=$nodes photons=1 revision=$revision mrfunction='".$want->{mrfunction}."' inputkey='".$want->{inputkey}."'$moreoptions $knobs\n";
    print "$cmd\n";
    system "$cmd" unless (++$already_did_cmd{$cmd} > 1);
}

sub mention_failed_job
{
    my $job = shift;
    print "# suggest investigating job id=".$job->{id}." -- failed with frozentokey=".$job->{frozentokey}." metakey=".$job->{metakey}."\n";
}

sub makeknobs
{
    my $function = shift @_;
    my $knobs = "";
    foreach (sort @_)
    {
	my ($k) = /^(.*)=/;
	if (exists $override{"$function/$k"})
	{
	    $knobs .= $k."=".$override{"$function/$k"};
	}
	else
	{
	    $knobs .= $_;
	}
	$knobs .= "\\n";
    }
    $knobs =~ s/\\n$//s;
    return $knobs;
}

sub get_job_times
{
    my $job = shift;
    my $atwhichfreeze = shift;
    return {
	nodeseconds => 0,
	elapsed => 0,
	slot_seconds => 0,
	success_seconds => 0,
	failure_seconds => 0,
	} if !$job;
    my $frozen = $whc->job_follow_thawedfrom ($job);
    $frozen = $whc->job_stats ($frozen->{id});

    my $times = get_job_times ($frozen, $job->{thawedfromkey});

    $job = $whc->job_stats ($job->{id});
    my $frozentimes;
    if ($atwhichfreeze
	&& $job->{meta_stats}->{frozentokeys}
	&& ($frozentimes = $job->{meta_stats}->{frozentokeys}->{$atwhichfreeze}))
    {
	printf STDERR ("Adding stats from %d at t=%d: %d elapsed, %d success, %d failure, %d idle\n",
		       $job->{id},
		       $frozentimes->{frozentime},
		       $frozentimes->{elapsed},
		       $frozentimes->{success_seconds},
		       $frozentimes->{failure_seconds},
		       $frozentimes->{idle_seconds}) if $ENV{MTR_DEBUG};
	foreach (keys %$times)
	{
	    $times->{$_} += $frozentimes->{$_};
	}
    }
    else
    {
	if ($ENV{MTR_DEBUG})
	{
	    if ($atwhichfreeze)
	    {
		print STDERR "Adding stats from ".$job->{id}.", using entire job because frozentokey ".$atwhichfreeze." not found\n";
	    }
	    else
	    {
		print STDERR "Adding stats from ".$job->{id}."\n";
	    }
	}
	foreach (keys %$times)
	{
	    $times->{$_} += ($job->{meta_stats}->{$_} || $job->{$_});
	}
    }
    return $times;
}

sub jsonjob
{
    my $label = shift;
    my $job = shift;
    my $x = { "label" => $label };
    if ($job)
    {
	if ($job->{id}) { $x->{id} = $job->{id} }
	if ($job->{success}) { $x->{status} = "done" }
	elsif ($job->{success} eq "0") { $x->{status} = "fail" }
	elsif ($job->{finishtime}) { $x->{status} = "fail" }
	elsif ($job->{starttime}) { $x->{status} = "run" }
	elsif ($job->{submittime}) { $x->{status} = "queue" }
	if (($x->{status} eq "run" || $x->{status} eq "fail")
	    &&
	    $job->{steps_done} =~ /\d/)
	{
	    my $steps = $job->{steps_done} + $job->{steps_running} + $job->{steps_todo};
	    $x->{progress} = $job->{steps_done} . "/" . $steps;
	}
	if ($x->{status} eq "done" && $job->{outputfiles})
	{
	    $x->{outputfiles} = $job->{outputfiles};
	}
    }
    return $x;
}

sub writejson
{
    my $file = shift;
    my $json = shift;
    open F, "+>>$file.tmp";
    flock F, LOCK_EX or do { close F; return; };
    seek F, 0, 0;
    truncate F, 0;
    print F "{\n\"workflow\": ".sprintjson("", $json)."\n}\n";
    close F;
    rename "$file.tmp", "$file";
}

sub sprintjson
{
    my $indent = shift;
    my $ob = shift;
    $indent .= "    ";
    if (ref $ob eq "HASH") { return "{ " . join (",\n$indent", map { qq{ "$_": }.sprintjson($indent, $ob->{$_}) } keys %$ob) . " }"; }
    if (ref $ob eq "ARRAY") { return "[ " . join (",\n$indent", map { sprintjson($indent, $_) } @$ob) . " ]"; }
    if (ref $ob eq "SCALAR") { return qq{"} . jsonquote($$ob) . qq{"}; }
    return qq{"} . jsonquote($ob) . qq{"};
}

sub jsonquote
{
    local $_ = shift;
    s/([\\\"\'])/\\$1/gs;
    s/\n/\\n/g;
    $_;
}

sub fork_downloader
{
    my $workfile = shift;
    my $child = fork();
    return if $child;
    return if !defined $child;
    exit 0 unless open L, "+>>", $workfile;
    exit 0 unless flock L, LOCK_EX;
    exit 1 unless open U, "<", "$workfile.isurl";
    my ($url) = <U>;
    $url =~ s/\'/\'\\\'\'/g;

    sysopen (F, "$workfile.lock", O_WRONLY|O_CREAT|O_EXCL) or exit 1;
    syswrite F, $url;
    close F;

    my $key = `wget -O - '$url' 2>>$workfile.wget-log | whput --in-manifest -`;
    chomp $key;
    if ($?)
    {
	sysopen (F, "$workfile.fail", O_WRONLY|O_CREAT|O_EXCL);
	close F;
	exit 0;
    }
    $key =~ s/\+[^,]*//g;
    symlink "$key", "$workfile.stored";
    rename "$workfile.lock", "$workfile.fetched";
    exit 0;
}


sub mapcheck_png
{
    my $me = shift;
    return "" if !$me;
    my $datahash = $me->{outputkey};
    return "" if !$datahash;
    my $pngpath = "$workdir/images/$datahash.mapcheck.png";
    if (-e $pngpath)
    {
	return "images/$datahash.mapcheck.png";
    }
    elsif (!-d "$workdir/images")
    {
	mkdir "$workdir/images";
    }
    if (sysopen F, "$pngpath.tmp", O_WRONLY|O_CREAT|O_EXCL)
    {
	my $child = fork();
	if ($child || !defined $child) { close F; return ""; }

	my $mapcheck_r = $0;
	$mapcheck_r =~ s{[^/]*$}{maq-mapcheck.r};
	system (qq{whget '$datahash/mapcheck.txt' - | egrep '^ *[0-9]' | perl -ne 'print ((split(":"))[2],"\\n")' > '$pngpath.in'})
	    == 0 or do { unlink "$pngpath.in", "$pngpath.tmp"; die "whget|egrep exited $?"; };
	system (qq{R --no-save --args infile="$pngpath.in" graph_w=3 graph_h=4 imagefile="$pngpath" < $mapcheck_r})
	    == 0 or do { unlink "$pngpath.in", "$pngpath.tmp"; die "R exited $?"; };
	unlink "$pngpath.in", "$pngpath.tmp";
	exit 0;
    }
}

__END__

client          apache          downloader      status
----------------------------------------------------------------
submit url
                w umd5.isurl.tmp
                w umd5.isurl
                                                r umd5.isurl
                w umd5
                                w umd5
                                l umd5
                                r umd5.isurl
                                w umd5.lock
                                l umd5.lock
                                download
                                w umd5.stored@
                                w umd5.fetched
                                                r umd5.stored@
